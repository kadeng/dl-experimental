{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: Could not open lock file /var/lib/dpkg/lock - open (13: Permission denied)\r\n",
      "E: Unable to lock the administration directory (/var/lib/dpkg/), are you root?\r\n"
     ]
    }
   ],
   "source": [
    "!apt-get install yasm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install ffmpeg and libavcodec-dev (plus related stuff) from\n",
    "https://launchpad.net/~mc3man/+archive/ubuntu/trusty-media\n",
    "\n",
    "Install OpenCV using the instructions from \n",
    "http://www.pyimagesearch.com/2015/06/22/install-opencv-3-0-and-python-2-7-on-ubuntu/\n",
    "\n",
    "In my case I had a build error related to missing CUDA libs, so the build command I used was\n",
    "\n",
    "    cmake -D CMAKE_BUILD_TYPE=RELEASE \\\n",
    "            -D CMAKE_INSTALL_PREFIX=/usr/local \\\n",
    "            -D INSTALL_C_EXAMPLES=OFF \\\n",
    "            -D INSTALL_PYTHON_EXAMPLES=ON \\\n",
    "            -D \"OPENCV_EXTRA_MODULES_PATH=../../opencv_contrib/modules\" \\\n",
    "            -D BUILD_EXAMPLES=ON \\\n",
    "            -D WITH_CUDA=OFF ..\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied (use --upgrade to upgrade): pytube in /usr/local/lib/python2.7/dist-packages\r\n",
      "Cleaning up...\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pytube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmmod: ERROR: Module nvidia_uvm is in use\n",
      "rmmod: ERROR: Module nvidia is in use by: nvidia_uvm\n",
      "insmod: ERROR: could not insert module /lib/modules/3.13.0-77-generic/kernel/drivers/video/nvidia.ko: File exists\n",
      "insmod: ERROR: could not insert module /lib/modules/3.13.0-77-generic/kernel/drivers/video/nvidia-uvm.ko: File exists\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# Reset GPU\n",
    "!sudo rmmod nvidia_uvm\n",
    "!sudo rmmod nvidia\n",
    "!sudo insmod /lib/modules/3.13.0-77-generic/kernel/drivers/video/nvidia.ko\n",
    "!sudo insmod /lib/modules/3.13.0-77-generic/kernel/drivers/video/nvidia-uvm.ko\n",
    "!echo \"OK\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory 'videos': File exists\n",
      "mkdir: cannot create directory 'imageseries': File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir videos\n",
    "!mkdir imageseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytube import YouTube\n",
    "\n",
    "# not necessary, just for demo purposes.\n",
    "from pprint import pprint\n",
    "\n",
    "yt = YouTube(\"https://www.youtube.com/watch?v=yim23IFJOyQ\")\n",
    "\n",
    "yt.set_filename('Chimpanzees1')\n",
    "# Once set, you can see all the codec and quality options YouTube has made\n",
    "# available for the perticular video by printing videos.\n",
    "\n",
    "# pprint(yt.get_videos())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "video = yt.get('mp4', '360p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# In this case, we'll need to specify both the codec (mp4) and resolution\n",
    "# (either 360p or 720p).\n",
    "\n",
    "# Okay, let's download it!\n",
    "video = yt.get('mp4', '360p')\n",
    "#video.download('./videos/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now let's try to read this using our fresh opencv build.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML, FileLink, display\n",
    "from base64 import b64encode\n",
    "def link_video(path):\n",
    "    src = FileLink(path)\n",
    "    video_tag = '<video controls alt=\"test\" src=\"%s\">' % (path)\n",
    "    \n",
    "    display(HTML(data=video_tag))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could read 1490 frames of shape (360, 640, 3) and dtype dtype('uint8')\n"
     ]
    }
   ],
   "source": [
    "vc = cv2.VideoCapture('videos/Chimpanzees1.mp4')\n",
    "frames = 0\n",
    "shape = None\n",
    "dtype = None\n",
    "while (True):\n",
    "    ret, img = vc.read()\n",
    "    # img should be an numpy ndarray of shape (width, heigth, channels)\n",
    "    if (not ret):\n",
    "        break\n",
    "    if (shape is None):\n",
    "        shape = img.shape\n",
    "    if (dtype is None):\n",
    "        dtype = img.dtype\n",
    "    frames+=1\n",
    "    \n",
    "print \"Could read %d frames of shape %r and dtype %r\" % (frames, shape, dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "h5f = h5py.File('/tmp/Chimpanzees1_6.hdf5',driver='core', backing_store=False)\n",
    "h5g = h5f.create_group('input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ishape = tuple([ frames ] + list(shape))\n",
    "ichunkshape = tuple([ 1 ] + list(shape))\n",
    "imaxshape = tuple([ None ] + list(shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import permutation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inframes = h5g.create_dataset('raw_hsl_frames', \n",
    "                             shape=ishape, dtype=np.float32, \n",
    "                             chunks=ichunkshape, maxshape=imaxshape,\n",
    "                             fletcher32=True, fillvalue=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWarning: cannot find svn location for rst2pdf==0.93.dev-r0\r\n",
      "\u001b[0mh5py==2.2.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip freeze |grep h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "permuted_indices = permutation(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "print shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame #50\n",
      "Frame #100\n",
      "Frame #150\n",
      "Frame #200\n",
      "Frame #250\n",
      "Frame #300\n",
      "Frame #350\n",
      "Frame #400\n",
      "Frame #450\n",
      "Frame #500\n",
      "Frame #550\n",
      "Frame #600\n",
      "Frame #650\n",
      "Frame #700\n",
      "Frame #750\n",
      "Frame #800\n",
      "Frame #850\n",
      "Frame #900\n",
      "Frame #950\n",
      "Frame #1000\n",
      "Frame #1050\n",
      "Frame #1100\n",
      "Frame #1150\n",
      "Frame #1200\n",
      "Frame #1250\n",
      "Frame #1300\n",
      "Frame #1350\n",
      "Frame #1400\n",
      "Frame #1450\n",
      "Read 1490 frames\n"
     ]
    }
   ],
   "source": [
    "vc = cv2.VideoCapture('videos/Chimpanzees1.mp4')\n",
    "frames = 0\n",
    "shape = None\n",
    "dtype = None\n",
    "while (True):\n",
    "    ret, img = vc.read()\n",
    "    if (not ret):\n",
    "        break\n",
    "    hsvimg = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    #print hsvimg.dtype\n",
    "    \n",
    "    hsvimgf = hsvimg.astype(np.float32) / 255.0\n",
    "    # img should be an numpy ndarray of shape (width, heigth, channels)\n",
    "    inframes[permuted_indices[frames],:,:,:] = hsvimgf\n",
    "    \n",
    "    hsvimg2 = (inframes[permuted_indices[frames],:,:,:] * 255.0).astype(np.uint8)\n",
    "    \n",
    "    #print np.sum(hsvimg-hsvimg2)\n",
    "    #bgrimg = cv2.cvtColor(hsvimg2, cv2.COLOR_HSV2BGR)\n",
    "    #print np.sum(img-bgrimg)\n",
    "    \n",
    "    #cv2.imwrite(\"videos/recoded1_%05d.png\" % (frames), bgrimg)\n",
    "    \n",
    "    frames+=1\n",
    "    if (frames % 50==0):\n",
    "        print \"Frame #%d\" % (frames)\n",
    "print \"Read %d frames\" % (frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access videos/Chimpanzees1.hdf5: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "ls -hs videos/Chimpanzees1.hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove ‘videos/imageseries*.png’: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!rm videos/imageseries*.png\n",
    "#!ffmpeg -i videos/Chimpanzees1.mp4 -r 6 -f image2 imageseries/Chimpanzees1_%05d.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove ‘videos/*.png’: No such file or directory\n",
      "Capoeira_Girl.mp4   Chimpanzees1_reconstructed2.mp4  Solar-System.mp4\n",
      "Capoeira_Movie.mp4  Chimpanzees1_reconstructed3.mp4\n",
      "Chimpanzees1.mp4    Chimpanzees.mp4\n"
     ]
    }
   ],
   "source": [
    "!rm videos/*.png\n",
    "!ls videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!rm videos/Chimpanzees1_recoded.mp4\n",
    "#!ffmpeg -i imageseries/Chimpanzees1_%05d.png -c:v libx264 -b:v 400k -vf format=yuv420p -maxrate:v 500k -bufsize 1000k  -r 10 -preset medium videos/Chimpanzees1_recoded.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.3M -rw-rw-r-- 1 nimbix nimbix 5.3M Apr 27 17:54 videos/Chimpanzees1.mp4\r\n",
      "1.6M -rw-rw-r-- 1 nimbix nimbix 1.6M Apr 29 10:40 videos/Chimpanzees1_reconstructed2.mp4\r\n",
      "100K -rw-rw-r-- 1 nimbix nimbix 100K May 11 18:05 videos/Chimpanzees1_reconstructed3.mp4\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lahs videos/Chimpanzees1*.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#link_video('videos/Chimpanzees1_recoded.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "from glob import glob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"epsilon\": 1e-07, \"floatx\": \"float32\", \"backend\": \"tensorflow\"}\r\n"
     ]
    }
   ],
   "source": [
    "!cat ~/.keras/keras.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Note:\n",
    "\n",
    "Read http://arxiv.org/pdf/1402.3337.pdf and use the ThresholdedReLu activation from http://keras.io/layers/advanced_activations/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten, Reshape, Permute\n",
    "from keras.layers.advanced_activations import ThresholdedReLU\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.convolutional import Convolution2D, ZeroPadding2D\n",
    "from keras.datasets import imdb\n",
    "from keras.optimizers import SGD\n",
    "from keras.regularizers import l1,l2,l1l2, ActivityRegularizer, activity_l1\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import keras.layers.convolutional as kconv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...X\n",
      "691200\n",
      "(None, 29, 53, 432)\n",
      "(None, 29, 53, 12, 12, 3)\n",
      "(None, 29, 12, 53, 12, 3)\n",
      "(None, 360, 640, 3)\n",
      "(None, 360, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "print 'Build model...X'\n",
    "\n",
    "num_feature_detectors=12*12*3\n",
    "tile_size=12\n",
    "receptive_field_size=16\n",
    "model = Sequential()\n",
    "model.add(Dropout(0.001, input_shape=ichunkshape[1:]))\n",
    "\n",
    "input_features = Convolution2D( name='encode_tiled_features', \n",
    "                        nb_filter=num_feature_detectors, nb_row=receptive_field_size,nb_col=receptive_field_size, \n",
    "                        subsample=(tile_size,tile_size), \n",
    "                        border_mode='valid', trainable=True,\n",
    "                        dim_ordering='tf' )\n",
    "\n",
    "\n",
    "print np.prod(ichunkshape[1:])\n",
    "model.add(input_features)\n",
    "\n",
    "print input_features.output_shape \n",
    "\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "decoder = Convolution2D( name='decode_tiled_features', \n",
    "                        nb_filter=tile_size*tile_size*3, nb_row=1,nb_col=1, subsample=(1,1),\n",
    "                        border_mode='same', trainable=True,\n",
    "                        dim_ordering='tf')\n",
    "\n",
    "model.add(decoder)\n",
    "model.add(Reshape(tuple(list(decoder.output_shape[1:3]) + [tile_size, tile_size, 3])))\n",
    "print model.output_shape\n",
    "model.add(Permute((1,3,2,4,5)))\n",
    "\n",
    "print model.output_shape\n",
    "model.add(Reshape((model.output_shape[1]*model.output_shape[2],model.output_shape[3]*model.output_shape[4],model.output_shape[5])))\n",
    "\n",
    "model.add(ZeroPadding2D(((ichunkshape[1]-model.output_shape[1])/2, (ichunkshape[2]-model.output_shape[2])/2), \n",
    "                        dim_ordering='tf'))\n",
    "\n",
    "print model.output_shape\n",
    "def mean_abs_error_all(y_true, y_pred):\n",
    "    return K.mean(K.abs(y_pred - y_true), axis=None)\n",
    "\n",
    "\n",
    "\n",
    "print model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/keras/models.py:332: UserWarning: \"class_mode\" argument is deprecated, please remove it.\n",
      "  warnings.warn('\"class_mode\" argument is deprecated, '\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss=mean_abs_error_all, class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inframesmem = np.array(inframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Over-Epoch 0\n",
      "Epoch 1/1\n",
      "520/500 [===============================] - 4s - loss: 0.0446 - val_loss: 0.0460\n",
      "Over-Epoch 1\n",
      "Epoch 1/1\n",
      "520/500 [===============================] - 4s - loss: 0.0447 - val_loss: 0.0436\n",
      "Over-Epoch 2\n",
      "Epoch 1/1\n",
      "360/500 [====================>.........] - ETA: 1s - loss: 0.0438"
     ]
    }
   ],
   "source": [
    "def data_generator(batchsize):\n",
    "    for i in range(10):\n",
    "        for j in permutation(1300):\n",
    "            bi = inframesmem[j:(j+batchsize),:,:,:]\n",
    "\n",
    "            yield bi,  bi\n",
    "\n",
    "for i in range(30):\n",
    "    print \"Over-Epoch %i\" % (i)\n",
    "    model.fit_generator(data_generator(40), validation_data=(inframes[1400:1430], inframes[1400:1430]),\n",
    "              show_accuracy=False, nb_epoch=1, samples_per_epoch=500, nb_worker=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('model1.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inframesm = np.array(inframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inframesm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-161762c73512>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minframesm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'inframesm' is not defined"
     ]
    }
   ],
   "source": [
    "type(inframesm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def data_generator(batchsize):\n",
    "    for i in range(10):\n",
    "        for j in permutation(1300):\n",
    "            bi = inframesm[j:(j+batchsize),:,:,:]\n",
    "            yield bi,  bi\n",
    "\n",
    "for i in range(1):\n",
    "    print \"Over-Epoch %i\" % (i)\n",
    "    model.fit_generator(data_generator(4), validation_data=(inframes[1400:1430], inframes[1400:1430]),\n",
    "              show_accuracy=False, nb_epoch=5, samples_per_epoch=400, nb_worker=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "K.floatx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import MaskedLayer\n",
    "import keras.backend as K\n",
    "\n",
    "_FLOATX = K.floatx()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'Build model...X'\n",
    "\n",
    "num_feature_detectors=16*16*4\n",
    "tile_size=16\n",
    "receptive_field_size=24\n",
    "model = Sequential()\n",
    "model.add(Dropout(0.1, input_shape=ichunkshape[1:]))\n",
    "\n",
    "input_features = Convolution2D( name='encode_tiled_features', \n",
    "                        nb_filter=num_feature_detectors, nb_row=receptive_field_size,nb_col=receptive_field_size, \n",
    "                        subsample=(tile_size,tile_size), \n",
    "                        border_mode='valid', trainable=True,\n",
    "                        dim_ordering='tf', activity_regularizer=activity_l1(0.0000005))\n",
    "\n",
    "\n",
    "model.add(input_features)\n",
    "model.add(PReLU())\n",
    "\n",
    "decoder = Convolution2D( name='decode_tiled_features', \n",
    "                        nb_filter=tile_size*tile_size*3, nb_row=1,nb_col=1, subsample=(1,1),\n",
    "                        border_mode='same', trainable=True,\n",
    "                        dim_ordering='tf')\n",
    "\n",
    "model.add(decoder)\n",
    "model.add(Reshape(tuple(list(decoder.output_shape[1:3]) + [tile_size, tile_size, 3])))\n",
    "print model.output_shape\n",
    "model.add(Permute((1,3,2,4,5)))\n",
    "\n",
    "print model.output_shape\n",
    "model.add(Reshape((model.output_shape[1]*model.output_shape[2],model.output_shape[3]*model.output_shape[4],model.output_shape[5])))\n",
    "\n",
    "model.add(ZeroPadding2D(((ichunkshape[1]-model.output_shape[1])/2, (ichunkshape[2]-model.output_shape[2])/2), \n",
    "                        dim_ordering='tf'))\n",
    "\n",
    "print model.output_shape\n",
    "def mean_abs_error_all(y_true, y_pred):\n",
    "    return K.mean(K.abs(y_pred - y_true), axis=None)\n",
    "\n",
    "\n",
    "\n",
    "print model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=mean_abs_error_all, class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def data_generator(batchsize):\n",
    "    for i in range(10):\n",
    "        perm = permutation(1300)\n",
    "        for i in range(len(perm)//batchsize):\n",
    "            bi = inframesmem[perm[i*batchsize:(i+1)*batchsize],:,:,:]\n",
    "            yield bi,  bi\n",
    "\n",
    "for i in range(1):\n",
    "    print \"Over-Epoch %i\" % (i)\n",
    "    model.fit_generator(data_generator(30), validation_data=(inframes[1400:1430], inframes[1400:1430]),\n",
    "              show_accuracy=False, nb_epoch=5, samples_per_epoch=400, nb_worker=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...X\n",
      "(None, 360, 640, 3)\n",
      "(None, 360, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "print 'Build model...X'\n",
    "\n",
    "num_feature_detectors=12*12*3\n",
    "tile_size=12\n",
    "receptive_field_size=16\n",
    "model = Sequential()\n",
    "model.add(Dropout(0.1, input_shape=ichunkshape[1:]))\n",
    "\n",
    "enc1 = Convolution2D( name='enc1', \n",
    "                        nb_filter=num_feature_detectors, nb_row=receptive_field_size,nb_col=receptive_field_size, \n",
    "                        subsample=(tile_size,tile_size), \n",
    "                        border_mode='valid', trainable=True,\n",
    "                        dim_ordering='tf', activity_regularizer=activity_l1(0.0000005))\n",
    "\n",
    "\n",
    "model.add(enc1)\n",
    "model.add(PReLU())\n",
    "model.add(Dropout(0.1))\n",
    "# ---------------\n",
    "tile_size2=2\n",
    "num_feature_detectors2=tile_size2*tile_size2*num_feature_detectors \n",
    "receptive_field_size2=2\n",
    "\n",
    "enc2 = Convolution2D( name='enc2', \n",
    "                        nb_filter=num_feature_detectors2, nb_row=receptive_field_size2,nb_col=receptive_field_size2, \n",
    "                        subsample=(tile_size2,tile_size2), \n",
    "                        border_mode='valid', trainable=True,\n",
    "                        dim_ordering='tf', activity_regularizer=activity_l1(0.0000005))\n",
    "\n",
    "\n",
    "model.add(enc2)\n",
    "model.add(PReLU())\n",
    "\n",
    "# --------------------\n",
    "\n",
    "dec2 = Convolution2D( name='dec2', \n",
    "                        nb_filter=tile_size2*tile_size2*num_feature_detectors, nb_row=1,nb_col=1, subsample=(1,1),\n",
    "                        border_mode='valid', trainable=True,\n",
    "                        dim_ordering='tf')\n",
    "\n",
    "model.add(dec2)\n",
    "# We need to reshape and reorder dimensions, so we can, at least in theory, do symmetric, layer-wise training...\n",
    "newshape2 = tuple(list(dec2.output_shape[1:3])+ [tile_size2, tile_size2, num_feature_detectors])\n",
    "model.add(Reshape(newshape2))\n",
    "model.add(Permute((1,3,2,4,5)))\n",
    "blockshape2 = (model.output_shape[1]*model.output_shape[2], model.output_shape[3]*model.output_shape[4], model.output_shape[5])\n",
    "\n",
    "model.add(Reshape(blockshape2))\n",
    "\n",
    "# --------------------\n",
    "\n",
    "dec1 = Convolution2D( name='dec1', \n",
    "                        nb_filter=tile_size*tile_size*3, nb_row=1,nb_col=1, subsample=(1,1),\n",
    "                        border_mode='same', trainable=True,\n",
    "                        dim_ordering='tf')\n",
    "model.add(dec1)\n",
    "newshape1 = tuple(list(dec1.output_shape[1:3])+ [tile_size, tile_size, 3])\n",
    "model.add(Reshape(newshape1))\n",
    "model.add(Permute((1,3,2,4,5)))\n",
    "\n",
    "blockshape1 = (model.output_shape[1]*model.output_shape[2],model.output_shape[3]*model.output_shape[4], model.output_shape[5])\n",
    "\n",
    "model.add(Reshape(blockshape1))\n",
    "\n",
    "model.add(ZeroPadding2D(((ichunkshape[1]-model.output_shape[1])/2, (ichunkshape[2]-model.output_shape[2])/2), \n",
    "                        dim_ordering='tf'))\n",
    "\n",
    "# --------------------\n",
    "\n",
    "print model.output_shape\n",
    "def mean_abs_error_all(y_true, y_pred):\n",
    "    return K.mean(K.abs(y_pred - y_true), axis=None)\n",
    "\n",
    "\n",
    "\n",
    "print model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "('The following error happened while compiling the node', GpuDnnConv{algo='small', inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode='valid', subsample=(12, 12), conv_mode='conv', precision='float32'}.0, Constant{1.0}, Constant{0.0}), '\\n', 'could not create cuDNN handle: CUDNN_STATUS_INTERNAL_ERROR', \"[GpuDnnConv{algo='small', inplace=True}(<CudaNdarrayType(float32, 4D)>, <CudaNdarrayType(float32, 4D)>, <CudaNdarrayType(float32, 4D)>, <CDataType{cudnnConvolutionDescriptor_t}>, Constant{1.0}, Constant{0.0})]\")",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-adb3cae2e2ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmean_abs_error_all\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/models.pyc\u001b[0m in \u001b[0;36mcompile\u001b[1;34m(self, optimizer, loss, class_mode, sample_weight_mode)\u001b[0m\n\u001b[0;32m    512\u001b[0m             \u001b[0mpredict_ins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 514\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_ins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupdates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    515\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_with_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_ins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupdates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict_ins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_updates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36mfunction\u001b[1;34m(inputs, outputs, updates)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 398\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mFunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupdates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, inputs, outputs, updates, **kwargs)\u001b[0m\n\u001b[0;32m    388\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m         self.function = theano.function(inputs, outputs, updates=updates,\n\u001b[1;32m--> 390\u001b[1;33m                                         allow_input_downcast=True, **kwargs)\n\u001b[0m\u001b[0;32m    391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function.pyc\u001b[0m in \u001b[0;36mfunction\u001b[1;34m(inputs, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)\u001b[0m\n\u001b[0;32m    315\u001b[0m                    \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m                    \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 317\u001b[1;33m                    output_keys=output_keys)\n\u001b[0m\u001b[0;32m    318\u001b[0m     \u001b[1;31m# We need to add the flag check_aliased inputs if we have any mutable or\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m     \u001b[1;31m# borrowed used defined inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/compile/pfunc.pyc\u001b[0m in \u001b[0;36mpfunc\u001b[1;34m(params, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[0;32m    477\u001b[0m                          \u001b[0maccept_inplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_inplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    478\u001b[0m                          \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 479\u001b[1;33m                          output_keys=output_keys)\n\u001b[0m\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36morig_function\u001b[1;34m(inputs, outputs, mode, accept_inplace, name, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[0;32m   1775\u001b[0m                    \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1776\u001b[0m                    \u001b[0moutput_keys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1777\u001b[1;33m             defaults)\n\u001b[0m\u001b[0;32m   1778\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1779\u001b[0m     \u001b[0mt2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, input_storage, trustme, storage_map)\u001b[0m\n\u001b[0;32m   1639\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlimit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1640\u001b[0m             _fn, _i, _o = self.linker.make_thunk(\n\u001b[1;32m-> 1641\u001b[1;33m                 input_storage=input_storage_lists, storage_map=storage_map)\n\u001b[0m\u001b[0;32m   1642\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1643\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlimit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlimit_orig\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/gof/link.pyc\u001b[0m in \u001b[0;36mmake_thunk\u001b[1;34m(self, input_storage, output_storage, storage_map)\u001b[0m\n\u001b[0;32m    688\u001b[0m         return self.make_all(input_storage=input_storage,\n\u001b[0;32m    689\u001b[0m                              \u001b[0moutput_storage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_storage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 690\u001b[1;33m                              storage_map=storage_map)[:3]\n\u001b[0m\u001b[0;32m    691\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmake_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_storage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/gof/vm.pyc\u001b[0m in \u001b[0;36mmake_all\u001b[1;34m(self, profiler, input_storage, output_storage, storage_map)\u001b[0m\n\u001b[0;32m   1035\u001b[0m                                                  \u001b[0mstorage_map\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m                                                  \u001b[0mcompute_map\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1037\u001b[1;33m                                                  no_recycling))\n\u001b[0m\u001b[0;32m   1038\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthunks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'lazy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m                     \u001b[1;31m# We don't want all ops maker to think about lazy Ops.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/sandbox/cuda/__init__.pyc\u001b[0m in \u001b[0;36mmake_thunk\u001b[1;34m(self, node, storage_map, compute_map, no_recycling)\u001b[0m\n\u001b[0;32m    286\u001b[0m                                     enable_cuda=False)\n\u001b[0;32m    287\u001b[0m         return super(GpuOp, self).make_thunk(node, storage_map,\n\u001b[1;32m--> 288\u001b[1;33m                                              compute_map, no_recycling)\n\u001b[0m\u001b[0;32m    289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m theano.compile.debugmode.default_make_thunk.append(\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36mmake_thunk\u001b[1;34m(self, node, storage_map, compute_map, no_recycling)\u001b[0m\n\u001b[0;32m    963\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m                 return self.make_c_thunk(node, storage_map, compute_map,\n\u001b[1;32m--> 965\u001b[1;33m                                          no_recycling)\n\u001b[0m\u001b[0;32m    966\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mNotImplementedError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMethodNotDefined\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Falling back on perform'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36mmake_c_thunk\u001b[1;34m(self, node, storage_map, compute_map, no_recycling)\u001b[0m\n\u001b[0;32m    877\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Trying CLinker.make_thunk'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    878\u001b[0m         outputs = cl.make_thunk(input_storage=node_input_storage,\n\u001b[1;32m--> 879\u001b[1;33m                                 output_storage=node_output_storage)\n\u001b[0m\u001b[0;32m    880\u001b[0m         \u001b[0mfill_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_input_filters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_output_filters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/gof/cc.pyc\u001b[0m in \u001b[0;36mmake_thunk\u001b[1;34m(self, input_storage, output_storage, storage_map, keep_lock)\u001b[0m\n\u001b[0;32m   1205\u001b[0m         cthunk, in_storage, out_storage, error_storage = self.__compile__(\n\u001b[0;32m   1206\u001b[0m             \u001b[0minput_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_map\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1207\u001b[1;33m             keep_lock=keep_lock)\n\u001b[0m\u001b[0;32m   1208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1209\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_CThunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcthunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_tasks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtasks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror_storage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/gof/cc.pyc\u001b[0m in \u001b[0;36m__compile__\u001b[1;34m(self, input_storage, output_storage, storage_map, keep_lock)\u001b[0m\n\u001b[0;32m   1150\u001b[0m                                     \u001b[0moutput_storage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m                                     \u001b[0mstorage_map\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1152\u001b[1;33m                                     keep_lock=keep_lock)\n\u001b[0m\u001b[0;32m   1153\u001b[0m         return (thunk,\n\u001b[0;32m   1154\u001b[0m                 [link.Container(input, storage) for input, storage in\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/gof/cc.pyc\u001b[0m in \u001b[0;36mcthunk_factory\u001b[1;34m(self, error_storage, in_storage, out_storage, storage_map, keep_lock)\u001b[0m\n\u001b[0;32m   1600\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1601\u001b[0m             module = get_module_cache().module_from_key(\n\u001b[1;32m-> 1602\u001b[1;33m                 key=key, lnk=self, keep_lock=keep_lock)\n\u001b[0m\u001b[0;32m   1603\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1604\u001b[0m         \u001b[0mvars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morphans\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/gof/cmodule.pyc\u001b[0m in \u001b[0;36mmodule_from_key\u001b[1;34m(self, key, lnk, keep_lock)\u001b[0m\n\u001b[0;32m   1172\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1173\u001b[0m                 \u001b[0mlocation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdlimport_workdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1174\u001b[1;33m                 \u001b[0mmodule\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlnk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile_cmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1175\u001b[0m                 \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__file__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1176\u001b[0m                 \u001b[1;32massert\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/gof/cc.pyc\u001b[0m in \u001b[0;36mcompile_cmodule\u001b[1;34m(self, location)\u001b[0m\n\u001b[0;32m   1511\u001b[0m                 \u001b[0mlib_dirs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlib_dirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1512\u001b[0m                 \u001b[0mlibs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlibs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1513\u001b[1;33m                 preargs=preargs)\n\u001b[0m\u001b[0;32m   1514\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1515\u001b[0m             \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/sandbox/cuda/nvcc_compiler.pyc\u001b[0m in \u001b[0;36mcompile_str\u001b[1;34m(module_name, src_code, location, include_dirs, lib_dirs, libs, preargs, rpaths, py_module, hide_symbols)\u001b[0m\n\u001b[0;32m    399\u001b[0m             \u001b[1;31m# touch the __init__ file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m             \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"__init__.py\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 401\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdlimport\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlib_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/gof/cmodule.pyc\u001b[0m in \u001b[0;36mdlimport\u001b[1;34m(fullpath, suffix)\u001b[0m\n\u001b[0;32m    329\u001b[0m             warnings.filterwarnings(\"ignore\",\n\u001b[0;32m    330\u001b[0m                                     message=\"numpy.ndarray size changed\")\n\u001b[1;32m--> 331\u001b[1;33m             \u001b[0mrval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__import__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    332\u001b[0m         \u001b[0mt1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m         \u001b[0mimport_time\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mt1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: ('The following error happened while compiling the node', GpuDnnConv{algo='small', inplace=True}(GpuContiguous.0, GpuContiguous.0, GpuAllocEmpty.0, GpuDnnConvDesc{border_mode='valid', subsample=(12, 12), conv_mode='conv', precision='float32'}.0, Constant{1.0}, Constant{0.0}), '\\n', 'could not create cuDNN handle: CUDNN_STATUS_INTERNAL_ERROR', \"[GpuDnnConv{algo='small', inplace=True}(<CudaNdarrayType(float32, 4D)>, <CudaNdarrayType(float32, 4D)>, <CudaNdarrayType(float32, 4D)>, <CDataType{cudnnConvolutionDescriptor_t}>, Constant{1.0}, Constant{0.0})]\")"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss=mean_abs_error_all, class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n",
      "[GpuElemwise{exp,no_inplace}(<CudaNdarrayType(float32, vector)>), HostFromGpu(GpuElemwise{exp,no_inplace}.0)]\n",
      "Looping 1000 times took 0.453555 seconds\n",
      "Result is [ 1.23178029  1.61879349  1.52278066 ...,  2.20771813  2.29967761\n",
      "  1.62323296]\n",
      "Used the gpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GRID K520 (CNMeM is enabled)\n"
     ]
    }
   ],
   "source": [
    "from theano import function, config, shared, sandbox\n",
    "import theano.tensor as T\n",
    "import numpy\n",
    "import time\n",
    "\n",
    "vlen = 10 * 30 * 768  # 10 x #cores x # threads per core\n",
    "iters = 1000\n",
    "\n",
    "rng = numpy.random.RandomState(22)\n",
    "x = shared(numpy.asarray(rng.rand(vlen), config.floatX))\n",
    "f = function([], T.exp(x))\n",
    "print(f.maker.fgraph.toposort())\n",
    "t0 = time.time()\n",
    "for i in range(iters):\n",
    "    r = f()\n",
    "t1 = time.time()\n",
    "print(\"Looping %d times took %f seconds\" % (iters, t1 - t0))\n",
    "print(\"Result is %s\" % (r,))\n",
    "if numpy.any([isinstance(x.op, T.Elemwise) for x in f.maker.fgraph.toposort()]):\n",
    "    print('Used the cpu')\n",
    "else:\n",
    "    print('Used the gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def data_generator(batchsize):\n",
    "    while True:\n",
    "        perm = permutation(1400)\n",
    "        for i in range(len(perm)//batchsize):\n",
    "            bi = inframesmem[perm[i*batchsize:(i+1)*batchsize],:,:,:]\n",
    "            yield bi,  bi\n",
    "\n",
    "for i in range(1):\n",
    "    print \"Over-Epoch %i\" % (i)\n",
    "    model.fit_generator(data_generator(40), validation_data=(inframes[1400:1480], inframes[1400:1480]),\n",
    "              show_accuracy=False, nb_epoch=10, samples_per_epoch=500, nb_worker=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('sparse_autoencoder_4layers.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!rm imageseries/*.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "j = 0\n",
    "c = 0\n",
    "for i in permuted_indices:\n",
    "    \n",
    "    \n",
    "    #print np.sum(hsvimg-hsvimg2)\n",
    "    fframe = inframes[i,:,:,:]\n",
    "    frame = (fframe * 255.0).astype(np.uint8)\n",
    "    \n",
    "    bgrimg = cv2.cvtColor(frame, cv2.COLOR_HSV2BGR)\n",
    "    \n",
    "    pframe = model.predict(fframe[np.newaxis,:,:,:], batch_size=1)\n",
    "    np.clip(pframe, 0.0, 1.0, pframe)\n",
    "    #print mean_squared_error_all\n",
    "    piframe = (pframe[0,:,:,:]*255.0).astype(np.uint8)\n",
    "    rgbimg = cv2.cvtColor(piframe, cv2.COLOR_HSV2BGR)\n",
    "    \n",
    "    j+=1\n",
    "    c+=1\n",
    "    cv2.imwrite(\"imageseries/reconstruction1_%05d.jpg\" % (c), rgbimg)\n",
    "    \n",
    "    if (j==800):\n",
    "        for z in range(200):\n",
    "            pframe = model.predict(pframe, batch_size=1)\n",
    "            np.clip(pframe, 0.0, 1.0, pframe)\n",
    "            #print mean_squared_error_all\n",
    "            piframe = (pframe[0,:,:,:]*255.0).astype(np.uint8)\n",
    "            rgbimg = cv2.cvtColor(piframe, cv2.COLOR_HSV2BGR)\n",
    "            c+=1\n",
    "            cv2.imwrite(\"imageseries/reconstruction1_%05d.jpg\" % (c), rgbimg)\n",
    "    if (j % 100==0):\n",
    "        me = np.mean(np.square((bgrimg.astype(np.float32)/255.0)-(rgbimg.astype(np.float32)/255.0)))\n",
    "        print \"Wrote image %d - MSE: %f\" % (j, me)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm imageseries/*.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!rm videos/Chimpanzees1_reconstructed2.mp4\n",
    "!ffmpeg -i imageseries/reconstruction1_%05d.jpg -c:v libx264 -b:v 400k -maxrate:v 500k -bufsize 1000k -r 10 -preset medium videos/Chimpanzees1_reconstructed2.mp4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!ls -hs videos/*.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "link_video('videos/Chimpanzees1_reconstructed2.mp4')\n",
    "#link_video('videos/Chimpanzees1_reconstructed2.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display(FileLink('videos/Chimpanzees1_reconstructed2.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class array(object) :\n",
    "    \"\"\"Simple Array object that support autodiff.\"\"\"\n",
    "    def __init__(self, value, name=None):\n",
    "        self.value = value\n",
    "        if name:\n",
    "            self.grad = lambda g : {name : g}\n",
    "\n",
    "    def __add__(self, other):\n",
    "        assert isinstance(other, int)\n",
    "        ret = array(self.value + other)\n",
    "        ret.grad = lambda g : self.grad(g)\n",
    "        return ret\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        assert isinstance(other, array)\n",
    "        ret = array(self.value * other.value)\n",
    "        def grad(g):\n",
    "            x = self.grad(g * other.value)\n",
    "            x.update(other.grad(g * self.value))\n",
    "            return x\n",
    "        ret.grad = grad\n",
    "        return ret\n",
    "\n",
    "# some examples\n",
    "a = array(1, 'a')\n",
    "b = array(2, 'b')\n",
    "c = b * a\n",
    "d = c + 1\n",
    "print d.value\n",
    "print d.grad(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(b*a).grad(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
