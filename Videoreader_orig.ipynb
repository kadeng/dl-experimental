{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!apt-get install yasm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install ffmpeg and libavcodec-dev (plus related stuff) from\n",
    "https://launchpad.net/~mc3man/+archive/ubuntu/trusty-media\n",
    "\n",
    "Install OpenCV using the instructions from \n",
    "http://www.pyimagesearch.com/2015/06/22/install-opencv-3-0-and-python-2-7-on-ubuntu/\n",
    "\n",
    "In my case I had a build error related to missing CUDA libs, so the build command I used was\n",
    "\n",
    "    cmake -D CMAKE_BUILD_TYPE=RELEASE \\\n",
    "            -D CMAKE_INSTALL_PREFIX=/usr/local \\\n",
    "            -D INSTALL_C_EXAMPLES=OFF \\\n",
    "            -D INSTALL_PYTHON_EXAMPLES=ON \\\n",
    "            -D \"OPENCV_EXTRA_MODULES_PATH=../../opencv_contrib/modules\" \\\n",
    "            -D BUILD_EXAMPLES=ON \\\n",
    "            -D WITH_CUDA=OFF ..\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install pytube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mkdir videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pytube import YouTube\n",
    "\n",
    "# not necessary, just for demo purposes.\n",
    "from pprint import pprint\n",
    "\n",
    "yt = YouTube(\"https://www.youtube.com/watch?v=yim23IFJOyQ\")\n",
    "\n",
    "yt.set_filename('Chimpanzees1')\n",
    "# Once set, you can see all the codec and quality options YouTube has made\n",
    "# available for the perticular video by printing videos.\n",
    "\n",
    "# pprint(yt.get_videos())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "video = yt.get('mp4', '360p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# In this case, we'll need to specify both the codec (mp4) and resolution\n",
    "# (either 360p or 720p).\n",
    "\n",
    "# Okay, let's download it!\n",
    "video = yt.get('mp4', '360p')\n",
    "video.download('./videos/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now let's try to read this using our fresh opencv build.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML, FileLink, display\n",
    "from base64 import b64encode\n",
    "def link_video(path):\n",
    "    src = FileLink(path)\n",
    "    video_tag = '<video controls alt=\"test\" src=\"%s\">' % (path)\n",
    "    \n",
    "    display(HTML(data=video_tag))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could read 1490 frames of shape (360, 640, 3) and dtype dtype('uint8')\n"
     ]
    }
   ],
   "source": [
    "vc = cv2.VideoCapture('videos/Chimpanzees1.mp4')\n",
    "frames = 0\n",
    "shape = None\n",
    "dtype = None\n",
    "while (True):\n",
    "    ret, img = vc.read()\n",
    "    # img should be an numpy ndarray of shape (width, heigth, channels)\n",
    "    if (not ret):\n",
    "        break\n",
    "    if (shape is None):\n",
    "        shape = img.shape\n",
    "    if (dtype is None):\n",
    "        dtype = img.dtype\n",
    "    frames+=1\n",
    "    \n",
    "print \"Could read %d frames of shape %r and dtype %r\" % (frames, shape, dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "h5f = h5py.File('videos/Chimpanzees1.hdf5', 'w')\n",
    "h5g = h5f.create_group('input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ishape = tuple([ frames ] + list(shape))\n",
    "ichunkshape = tuple([ 1 ] + list(shape))\n",
    "imaxshape = tuple([ None ] + list(shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy.random import permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inframes = h5g.create_dataset('raw_hsl_frames', \n",
    "                             shape=ishape, dtype=np.float32, \n",
    "                             chunks=ichunkshape, maxshape=imaxshape,\n",
    "                             fletcher32=True, fillvalue=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "permuted_indices = permutation(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame #50\n",
      "Frame #100\n",
      "Frame #150\n",
      "Frame #200\n",
      "Frame #250\n",
      "Frame #300\n",
      "Frame #350\n",
      "Frame #400\n",
      "Frame #450\n",
      "Frame #500\n",
      "Frame #550\n",
      "Frame #600\n",
      "Frame #650\n",
      "Frame #700\n",
      "Frame #750\n",
      "Frame #800\n",
      "Frame #850\n",
      "Frame #900\n",
      "Frame #950\n",
      "Frame #1000\n",
      "Frame #1050\n",
      "Frame #1100\n",
      "Frame #1150\n",
      "Frame #1200\n",
      "Frame #1250\n",
      "Frame #1300\n",
      "Frame #1350\n",
      "Frame #1400\n",
      "Frame #1450\n",
      "Read 1490 frames\n"
     ]
    }
   ],
   "source": [
    "vc = cv2.VideoCapture('videos/Chimpanzees1.mp4')\n",
    "frames = 0\n",
    "shape = None\n",
    "dtype = None\n",
    "while (True):\n",
    "    ret, img = vc.read()\n",
    "    if (not ret):\n",
    "        break\n",
    "    hsvimg = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    #print hsvimg.dtype\n",
    "    \n",
    "    hsvimgf = hsvimg.astype(np.float32) / 255.0\n",
    "    # img should be an numpy ndarray of shape (width, heigth, channels)\n",
    "    inframes[permuted_indices[frames],:,:,:] = hsvimgf\n",
    "    \n",
    "    hsvimg2 = (inframes[permuted_indices[frames],:,:,:] * 255.0).astype(np.uint8)\n",
    "    \n",
    "    #print np.sum(hsvimg-hsvimg2)\n",
    "    #bgrimg = cv2.cvtColor(hsvimg2, cv2.COLOR_HSV2BGR)\n",
    "    #print np.sum(img-bgrimg)\n",
    "    \n",
    "    #cv2.imwrite(\"videos/recoded1_%05d.png\" % (frames), bgrimg)\n",
    "    \n",
    "    frames+=1\n",
    "    if (frames % 50==0):\n",
    "        print \"Frame #%d\" % (frames)\n",
    "print \"Read %d frames\" % (frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ls -hs videos/Chimpanzees1.hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rm -rf videos/Chimpanzee1RegionTest_*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!rm videos/Chimpanzees1_*.png\n",
    "!ffmpeg -i videos/Chimpanzees1.mp4 -r 6 -f image2 videos/Chimpanzees1_%05d.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!ls videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!rm videos/Chimpanzees1_recoded.mp4\n",
    "!ffmpeg -i videos/Chimpanzees1_%05d.png -b 512 -c:v libx264 -b:v 400k -r 10 -preset medium videos/Chimpanzees1_recoded.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!ls -lahs videos/Chimpanzees1*.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "link_video('videos/Chimpanzees1_recoded.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "from glob import glob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cat ~/.keras/keras.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Note:\n",
    "\n",
    "Read http://arxiv.org/pdf/1402.3337.pdf and use the ThresholdedReLu activation from http://keras.io/layers/advanced_activations/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten, Reshape\n",
    "from keras.layers.advanced_activations import ThresholdedReLU\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.convolutional import Convolution2D, ZeroPadding2D\n",
    "from keras.datasets import imdb\n",
    "from keras.optimizers import SGD\n",
    "from keras.regularizers import l1,l2,l1l2\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.layers.convolutional as kconv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "(24, 24, 3, 768)\n",
      "(768,)\n",
      "(24, 24, 3, 768)\n",
      "(None, 360, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "print 'Build model...'\n",
    "\n",
    "num_feature_detectors=16*16*3\n",
    "tile_size=16\n",
    "receptive_field_size=24\n",
    "model = Sequential()\n",
    "#model.add(Dropout(0.001, input_shape=ichunkshape[1:]))\n",
    "w1 = np.zeros(shape=(receptive_field_size, receptive_field_size, 3, num_feature_detectors), dtype=np.float32)\n",
    "b1 = np.zeros(shape=(num_feature_detectors,), dtype=np.float32)\n",
    "off = (receptive_field_size - tile_size) / 2\n",
    "for i in range(tile_size):\n",
    "    for j in range(tile_size):\n",
    "        for h in range(3):\n",
    "            w1[off+i,off+j,h, i*3*tile_size+j*3+h] = 1.0\n",
    "\n",
    "input_features = Convolution2D( name='encode_tiled_features', \n",
    "                        nb_filter=num_feature_detectors, nb_row=receptive_field_size,nb_col=receptive_field_size, \n",
    "                        subsample=(tile_size,tile_size), weights=[w1,b1],\n",
    "                        border_mode='valid', trainable=False,\n",
    "                        dim_ordering='tf', input_shape=ichunkshape[1:] )\n",
    "\n",
    "\n",
    "model.add(input_features)\n",
    "print K.get_value(input_features.params[0]).shape\n",
    "print K.get_value(input_features.params[1]).shape\n",
    "print w1.shape\n",
    "#model.add(Activation('relu'))\n",
    "decoder = Convolution2D( name='decode_tiled_features', \n",
    "                        nb_filter=tile_size*tile_size*3, nb_row=1,nb_col=1, subsample=(1,1),\n",
    "                        border_mode='valid',\n",
    "                        dim_ordering='tf')\n",
    "model.add(decoder)\n",
    "model.add(Reshape(dims=(decoder.output_shape[1]*tile_size,decoder.output_shape[2]*tile_size, 3)))\n",
    "model.add(ZeroPadding2D(((ichunkshape[1]-model.output_shape[1])/2, (ichunkshape[2]-model.output_shape[2])/2), \n",
    "                        dim_ordering='tf'))\n",
    "\n",
    "def mean_squared_error_all(y_true, y_pred):\n",
    "    return K.mean(K.abs(y_pred - y_true), axis=None)\n",
    "\n",
    "\n",
    "\n",
    "print model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = SGD(lr=0.01, momentum=0.6, decay=0.0, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=opt, loss=mean_squared_error_all, class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "print \"OK\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Over-Epoch 0\n",
      "Epoch 1/30\n",
      "198/200 [============================>.] - ETA: 0s - loss: 0.2636"
     ]
    }
   ],
   "source": [
    "def data_generator(batchsize):\n",
    "    for i in range(10):\n",
    "        for j in permutation(1300):\n",
    "            bi = inframes[j:(j+batchsize),:,:,:]\n",
    "            yield bi,  bi\n",
    "    \n",
    "for i in range(10):\n",
    "    print \"Over-Epoch %i\" % (i)\n",
    "    model.fit_generator(data_generator(3), validation_data=(inframes[1400:1500], inframes[1400:1500]),\n",
    "              show_accuracy=False, nb_epoch=30, samples_per_epoch=200, nb_worker=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch at 390\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Argument sequence too long",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-c3c11d534f3b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mbi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mba\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0mbi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0mba\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-36-f254b67dba5e>\u001b[0m in \u001b[0;36mdata_generator\u001b[1;34m(batchsize)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpermutation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[1;34m\"Batch at %d\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mbi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minframes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[0mbi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;32myield\u001b[0m \u001b[0mbi\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mbi\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/tmp/pip_build_root/h5py/h5py/_objects.c:2508)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/tmp/pip_build_root/h5py/h5py/_objects.c:2461)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/h5py/_hl/dataset.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m         \u001b[1;31m# Perform the dataspace selection.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 431\u001b[1;33m         \u001b[0mselection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdsid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    432\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mselection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnselect\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/h5py/_hl/selections.pyc\u001b[0m in \u001b[0;36mselect\u001b[1;34m(shape, args, dsid)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[0msel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSimpleSelection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m     \u001b[0msel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/h5py/_hl/selections.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    264\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 266\u001b[1;33m         \u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscalar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_handle_simple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect_hyperslab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/h5py/_hl/selections.pyc\u001b[0m in \u001b[0;36m_handle_simple\u001b[1;34m(shape, args)\u001b[0m\n\u001b[0;32m    506\u001b[0m         \u001b[0mselected\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    507\u001b[0m     \"\"\"\n\u001b[1;32m--> 508\u001b[1;33m     \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_expand_ellipsis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    509\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m     \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/h5py/_hl/selections.pyc\u001b[0m in \u001b[0;36m_expand_ellipsis\u001b[1;34m(args, rank)\u001b[0m\n\u001b[0;32m    493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_args\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mrank\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 495\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Argument sequence too long\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    496\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfinal_args\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Argument sequence too long"
     ]
    }
   ],
   "source": [
    "for bi, ba in data_generator(2):\n",
    "    print bi.shape\n",
    "    print ba.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(inframes[1:4], batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reverse_permute = np.array(permuted_indices, dtype=np.int32)\n",
    "for i in range(frames):\n",
    "    reverse_permute[permuted_indices[i]]=i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "j = 0\n",
    "for i in permuted_indices:\n",
    "    \n",
    "    \n",
    "    #print np.sum(hsvimg-hsvimg2)\n",
    "    fframe = inframes[i,:,:,:]\n",
    "    frame = (fframe * 255.0).astype(np.uint8)\n",
    "    \n",
    "    bgrimg = cv2.cvtColor(frame, cv2.COLOR_HSV2BGR)\n",
    "    \n",
    "    #print np.sum(img-bgrimg)\n",
    "    cv2.imwrite(\"videos/recoded1_%05d.png\" % (frames), bgrimg)\n",
    "    \n",
    "    pframe = model.predict(fframe[np.newaxis,:,:,:], batch_size=1)\n",
    "    #print mean_squared_error_all\n",
    "    piframe = (pframe[0,:,:,:]*255.0).astype(np.uint8)\n",
    "    rgbimg = cv2.cvtColor(piframe, cv2.COLOR_HSV2BGR)\n",
    "        \n",
    "    j+=1\n",
    "    cv2.imwrite(\"videos/reconstruction1_%05d.png\" % (j), rgbimg)\n",
    "\n",
    "    if (j % 10==0):\n",
    "        me = np.mean(np.square((bgrimg.astype(np.float32)/255.0)-(rgbimg.astype(np.float32)/255.0)))\n",
    "        print \"Wrote image %d - MSE: %f\" % (j, me)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!ffmpeg -i videos/reconstruction1_%05d.png -b 512 -c:v libx264 -b:v 400k -r 10 -preset medium videos/Chimpanzees1_reconstruction.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!ls -hs videos/*.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "link_video('videos/Chimpanzees1_reconstruction.mp4')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
