{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install ffmpeg and libavcodec-dev (plus related stuff) from\n",
    "https://launchpad.net/~mc3man/+archive/ubuntu/trusty-media\n",
    "\n",
    "Install OpenCV using the instructions from \n",
    "http://www.pyimagesearch.com/2015/06/22/install-opencv-3-0-and-python-2-7-on-ubuntu/\n",
    "\n",
    "In my case I had a build error related to missing CUDA libs, so the build command I used was\n",
    "\n",
    "    cmake -D CMAKE_BUILD_TYPE=RELEASE \\\n",
    "            -D CMAKE_INSTALL_PREFIX=/usr/local \\\n",
    "            -D INSTALL_C_EXAMPLES=OFF \\\n",
    "            -D INSTALL_PYTHON_EXAMPLES=ON \\\n",
    "            -D \"OPENCV_EXTRA_MODULES_PATH=../../opencv_contrib/modules\" \\\n",
    "            -D BUILD_EXAMPLES=ON \\\n",
    "            -D WITH_CUDA=OFF ..\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "print \"OK\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!sudo pip install pytube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reset GPU\n",
    "#!sudo rmmod nvidia_uvm\n",
    "#!sudo rmmod nvidia\n",
    "#!sudo insmod /lib/modules/3.13.0-77-generic/kernel/drivers/video/nvidia.ko\n",
    "#!sudo insmod /lib/modules/3.13.0-77-generic/kernel/drivers/video/nvidia-uvm.ko\n",
    "#!echo \"OK\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!mkdir videos\n",
    "!mkdir imageseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!ls videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pytube import YouTube\n",
    "\n",
    "# not necessary, just for demo purposes.\n",
    "from pprint import pprint\n",
    "\n",
    "yt = YouTube(\"https://www.youtube.com/watch?v=yim23IFJOyQ\")\n",
    "\n",
    "yt.set_filename('Chimpanzees1')\n",
    "# Once set, you can see all the codec and quality options YouTube has made\n",
    "# available for the perticular video by printing videos.\n",
    "\n",
    "# pprint(yt.get_videos())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#video = yt.get('mp4', '360p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# In this case, we'll need to specify both the codec (mp4) and resolution\n",
    "# (either 360p or 720p).\n",
    "\n",
    "# Okay, let's download it!\n",
    "video = yt.get('mp4', '360p')\n",
    "#video.download('./videos/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now let's try to read this using our fresh opencv build.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML, FileLink, display\n",
    "from base64 import b64encode\n",
    "def link_video(path):\n",
    "    src = FileLink(path)\n",
    "    video_tag = '<video controls alt=\"test\" src=\"%s\">' % (path)\n",
    "    \n",
    "    display(HTML(data=video_tag))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could read 1490 frames of shape (360, 640, 3) and dtype dtype('uint8')\n"
     ]
    }
   ],
   "source": [
    "vc = cv2.VideoCapture('videos/Chimpanzees1.mp4')\n",
    "frames = 0\n",
    "shape = None\n",
    "dtype = None\n",
    "while (True):\n",
    "    ret, img = vc.read()\n",
    "    # img should be an numpy ndarray of shape (width, heigth, channels)\n",
    "    if (not ret):\n",
    "        break\n",
    "    if (shape is None):\n",
    "        shape = img.shape\n",
    "    if (dtype is None):\n",
    "        dtype = img.dtype\n",
    "    frames+=1\n",
    "    \n",
    "print \"Could read %d frames of shape %r and dtype %r\" % (frames, shape, dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import h5py\n",
    "\n",
    "#h5f = h5py.File('videos/Chimpanzees1_7.hdf5',driver='core', backing_store=True)\n",
    "#h5f = h5py.File('/tmp/Chimpanzees1_7.hdf5')\n",
    "#h5g = h5f.create_group('input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360, 640, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rshape = [ shape[2],shape[0], shape[1] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ishape = tuple([ frames ] + list(rshape))\n",
    "ichunkshape = tuple([ 1 ] + list(rshape))\n",
    "imaxshape = tuple([ None ] + list(rshape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import permutation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#inframes = h5g.create_dataset('raw_hsl_frames', \n",
    "#                             shape=ishape, dtype=np.float32, \n",
    "#                             chunks=ichunkshape, maxshape=imaxshape,\n",
    "#                             fletcher32=True, fillvalue=0)\n",
    "#\n",
    "inframes = np.zeros(shape=ishape, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "permuted_indices = permutation(range(frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([119, 797, 583, ..., 241,  39, 999])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permuted_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame #300\n",
      "Frame #600\n",
      "Frame #900\n",
      "Frame #1200\n",
      "Read 1490 frames\n"
     ]
    }
   ],
   "source": [
    "vc = cv2.VideoCapture('videos/Chimpanzees1.mp4')\n",
    "frames = 0\n",
    "shape = None\n",
    "dtype = None\n",
    "while (True):\n",
    "    ret, img = vc.read()\n",
    "    if (not ret):\n",
    "        break\n",
    "    hsvimg = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    \n",
    "    hsvimgf = hsvimg.astype(np.float32) / 255.0\n",
    "    hsvimgf = hsvimgf.swapaxes(2,0).swapaxes(1,2)\n",
    "    # img should be an numpy ndarray of shape (width, heigth, channels)\n",
    "    inframes[permuted_indices[frames],:,:,:] = hsvimgf\n",
    "    \n",
    "    #hsvimg2 = (inframes[permuted_indices[frames],:,:,:] * 255.0).astype(np.uint8)\n",
    "    \n",
    "    #print np.sum(hsvimg-hsvimg2)\n",
    "    #bgrimg = cv2.cvtColor(hsvimg2, cv2.COLOR_HSV2BGR)\n",
    "    #print np.sum(img-bgrimg)\n",
    "    \n",
    "    #cv2.imwrite(\"videos/recoded1_%05d.png\" % (frames), bgrimg)\n",
    "    \n",
    "    frames+=1\n",
    "    if (frames % 300==0):\n",
    "        print \"Frame #%d\" % (frames)\n",
    "print \"Read %d frames\" % (frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#inframesmem = np.array(inframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!rm videos/Chimpanzees1_recoded.mp4\n",
    "#!ffmpeg -i imageseries/Chimpanzees1_%05d.png -c:v libx264 -b:v 400k -vf format=yuv420p -maxrate:v 500k -bufsize 1000k  -r 10 -preset medium videos/Chimpanzees1_recoded.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#link_video('videos/Chimpanzees1_recoded.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "from glob import glob\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MXNet ##\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06:38:46 DEBUG:test\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "reload(logging)\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s:%(message)s', level=logging.DEBUG, datefmt='%I:%M:%S')\n",
    "logging.debug(\"test\")\n",
    "\n",
    "import os\n",
    "# Comment this out, once it all works\n",
    "#os.environ['MXNET_ENGINE_TYPE']='NaiveEngine'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import mxnet.io as mxio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06:38:58 DEBUG:test\n"
     ]
    }
   ],
   "source": [
    "logging.debug(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = mx.nd.ones((2,3), mx.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = mx.nd.zeros((2,3), mx.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mxnet.ndarray.NDArray at 0x2b2d47f2f310>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1:] = 2\n",
    "a.copyto(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1.],\n",
       "       [ 2.,  2.,  2.]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.asnumpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "windowsize=128\n",
    "batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1L, 2L, 2L)\n"
     ]
    }
   ],
   "source": [
    "a = mx.nd.ones(shape=(2,2,2))\n",
    "print a[1:2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MultiplyMaskOp(mx.operator.CustomOp):\n",
    "    \n",
    "    def forward(self, is_train, req, in_data, out_data, aux):\n",
    "        img_channels = in_data[1].asnumpy()\n",
    "        mask = in_data[0].asnumpy()\n",
    "        \n",
    "        if req[0]=='null':\n",
    "            return\n",
    "        \n",
    "        shp = list(img_channels.shape)\n",
    "        shp[1] += 1\n",
    "        \n",
    "        out = np.zeros(shape=tuple(shp))\n",
    "        out[:,0:1,:,:] = mask\n",
    "        out[:,1:,:,:] = img_channels*mask # Automatic broadcasting to the rescue\n",
    "        \n",
    "        if req[0]=='write':\n",
    "            out_data[0][:] = out\n",
    "        elif req[0]=='add':\n",
    "            out_data[0][:] += out\n",
    "                \n",
    "    def backward(self, req, out_grad, in_data, out_data, in_grad, aux):\n",
    "        if req[0]=='null':\n",
    "            return\n",
    "        \n",
    "        mask = in_data[0]\n",
    "        img_channels = in_data[1]\n",
    "        \n",
    "        img_grad = out_data[:,1:]\n",
    "        mask_grad = out_data[:,0:1]\n",
    "        \n",
    "        # Gradient of mask is copied through\n",
    "        \n",
    "        if req[0]=='write':\n",
    "            in_grad[0][:] = mask_grad\n",
    "        elif req[0]=='add':\n",
    "            in_grad[0][:] += mask_grad\n",
    "           \n",
    "        img_grad = np.ones(img_channels.shape)\n",
    "        for i in range(3):\n",
    "            # Product rule applies for image channels\n",
    "            chan_grad = mx.nd.add(mx.nd.multiply(img_channels[:,i:i+1], mask_grad), \n",
    "                                  mx.nd.multiply(img_grad[:,i:i+1], mask) )\n",
    "            img_grad[:,i,:,:] = chan.asnumpy()\n",
    "            \n",
    "        if req[1]=='write':\n",
    "            in_grad[1][:] = img_grad    \n",
    "        elif req[1]=='add':\n",
    "            in_grad[1][:] += img_grad\n",
    "            \n",
    "@mx.operator.register(\"maskmult\")\n",
    "class MultiplyMaskOpProp(mx.operator.CustomOpProp):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MultiplyMaskOpProp, self).__init__()\n",
    "        \n",
    "    def list_arguments(self):\n",
    "        return ['mask', 'data']\n",
    "\n",
    "    def list_outputs(self):\n",
    "        return ['masked_data']\n",
    "\n",
    "    def infer_shape(self, in_shape):\n",
    "        mask_shape = list(in_shape[0])\n",
    "        data_shape = list(in_shape[1])\n",
    "        data_shape[1]+=1\n",
    "        return in_shape, [data_shape], []\n",
    "    \n",
    "    def create_operator(self, ctx, shapes, dtypes):\n",
    "        return MultiplyMaskOp()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = mx.symbol.Variable('data')\n",
    "y = mx.symbol.Variable('y')\n",
    "\n",
    "net = data\n",
    "dil = 1\n",
    "for d in range(1,5):\n",
    "    net = mx.symbol.Convolution(net, kernel=(1,1), num_filter=d*16+2, name='squeeze%d' % (d), workspace=200)\n",
    "    net1 = mx.symbol.LeakyReLU(net, act_type='prelu')\n",
    "    net = mx.symbol.Convolution(net1, kernel=(3,3), num_filter=32*d+2, dilate=(dil,dil), name='conv%d' % (d), workspace=200)\n",
    "    net2 = mx.symbol.LeakyReLU(net, act_type='prelu')\n",
    "    \n",
    "    # We need to crop net1, since it can be larger than net2 \n",
    "    net1 = mx.symbol.Crop(net1, net2, center_crop=True)  \n",
    "    \n",
    "    net = mx.symbol.Concat(net1,net2)\n",
    "    #print net.infer_shape(data=(10,4,64,64))\n",
    "    net = mx.symbol.DropoutAllChannels(net, p=0.05)\n",
    "    dil *= 2\n",
    "\n",
    "net = mx.symbol.Convolution(net, kernel=(1,1), num_filter=128, name='squeeze_final', workspace=200)\n",
    "net = mx.symbol.Dropout(net, p=0.2)\n",
    "net = mx.symbol.LeakyReLU(net, act_type='prelu')\n",
    "   \n",
    "net = mx.symbol.Convolution(net, kernel=(3,3), num_filter=3, name='decoder',  workspace=200)\n",
    "net = mx.symbol.Activation(net, name='final_activation', act_type='sigmoid')\n",
    "out = mx.symbol.MAERegressionOutput(data=net, label=y, name='output_')\n",
    "\n",
    "def get_output_resolution(input_shape=(10, 3, 640, 480)):\n",
    "    mshape = list(input_shape)\n",
    "    mshape[1] = 1\n",
    "    return net.infer_shape(data=input_shape, mask=mshape)[-2][0][2:]\n",
    "\n",
    "def get_middle_slice(X):\n",
    "    res = get_output_resolution(X.shape)\n",
    "    dx = (X.shape[2]-res[0]) // 2\n",
    "    dy = (X.shape[3]-res[1]) // 2\n",
    "    return X[:,:,dx:X.shape[2]-dx,dy:X.shape[3]-dy]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 1\n",
    "#model = mx.model.FeedForward(ctx=mx.cpu(), symbol=out, num_epoch=num_epoch, optimizer='sgd',\n",
    "#                             learning_rate=0.05, momentum=0.9, wd=0.00001)\n",
    "\n",
    "model = mx.model.FeedForward(ctx=[ mx.gpu(i) for i in range(1)], symbol=out, num_epoch=num_epoch, optimizer='adam')\n",
    "print \"OK\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy.lib.stride_tricks import as_strided\n",
    "\n",
    "def tile_array(a, b1, b2):\n",
    "    r, c = a.shape\n",
    "    rs, cs = a.strides\n",
    "    x = as_strided(a, (r, b1, c, b2), (rs, 0, cs, 0))\n",
    "    return x.reshape(r*b1, c*b2)\n",
    "\n",
    "def tile_batch_mask(shape, p, tile_x, tile_y):\n",
    "    target = np.ones(shape=shape, dtype=np.float32)\n",
    "    assert(shape[1]==1)\n",
    "    for i in range(target.shape[0]):\n",
    "        \n",
    "        rnd_shape = (shape[2] / tile_x, shape[3] / tile_y)\n",
    "        rnd = (np.random.random(rnd_shape)<=p).astype(np.float32)\n",
    "        tiled = tile_array(rnd, tile_x, tile_y)\n",
    "        target[i,0,:,:] = tiled\n",
    "    return target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "MXNetError",
     "evalue": "[18:41:21] src/io/local_filesys.cc:149: Check failed: allow_null  LocalFileSystem: fail to open \"dilated-autoencoder2_4-symbol.json\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMXNetError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-39a1d79a21ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dilated-autoencoder2_4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/mxnet-0.7.0-py2.7.egg/mxnet/model.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(prefix, epoch, ctx, **kwargs)\u001b[0m\n\u001b[1;32m    837\u001b[0m         \u001b[0;34m-\u001b[0m \u001b[0;34m`\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m`\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0msaved\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m         \"\"\"\n\u001b[0;32m--> 839\u001b[0;31m         \u001b[0msymbol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    840\u001b[0m         return FeedForward(symbol, ctx=ctx,\n\u001b[1;32m    841\u001b[0m                            \u001b[0marg_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maux_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/mxnet-0.7.0-py2.7.egg/mxnet/model.pyc\u001b[0m in \u001b[0;36mload_checkpoint\u001b[0;34m(prefix, epoch)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;34m-\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mloaded\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m`\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m     \"\"\"\n\u001b[0;32m--> 364\u001b[0;31m     \u001b[0msymbol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s-symbol.json'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m     \u001b[0msave_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s-%04d.params'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0marg_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/mxnet-0.7.0-py2.7.egg/mxnet/symbol.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m    956\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fname need to be string'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m     \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSymbolHandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 958\u001b[0;31m     \u001b[0mcheck_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMXSymbolCreateFromFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    959\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mSymbol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/mxnet-0.7.0-py2.7.egg/mxnet/base.pyc\u001b[0m in \u001b[0;36mcheck_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \"\"\"\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMXNetError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMXGetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMXNetError\u001b[0m: [18:41:21] src/io/local_filesys.cc:149: Check failed: allow_null  LocalFileSystem: fail to open \"dilated-autoencoder2_4-symbol.json\""
     ]
    }
   ],
   "source": [
    "model.num_epoch = 1\n",
    "model.load('dilated-autoencoder2_4', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06:42:49 INFO:Start training with [gpu(0)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Windowed Batch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06:43:10 INFO:Epoch[0] Resetting Data Iterator\n",
      "06:43:10 INFO:Epoch[0] Time cost=20.413\n",
      "06:43:13 INFO:Epoch[0] Validation-mae=0.150589\n",
      "06:43:13 INFO:Start training with [gpu(0)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Windowed Batch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06:43:29 INFO:Epoch[0] Resetting Data Iterator\n",
      "06:43:29 INFO:Epoch[0] Time cost=15.975\n",
      "06:43:32 INFO:Epoch[0] Validation-mae=0.161410\n"
     ]
    }
   ],
   "source": [
    "\n",
    "chunk_size = batch_size*16\n",
    "for i in range(2):\n",
    "    window_off_x =  np.random.randint(0, inframes.shape[2]-windowsize)\n",
    "    window_off_y = np.random.randint(0, inframes.shape[3]-windowsize)\n",
    "    start = np.random.randint(0, 1300-chunk_size)\n",
    "    train_X = inframes[start:start+chunk_size,:,window_off_x:window_off_x+windowsize,window_off_y:window_off_y+windowsize]\n",
    "    train_y = get_middle_slice(train_X)\n",
    "    mask_shape = list(train_X.shape)\n",
    "    mask_shape[1] = 1\n",
    "    if (i%2==0):\n",
    "        mask = tile_batch_mask(mask_shape, 0.80, 16, 16)\n",
    "    else:\n",
    "        mask = tile_batch_mask(mask_shape, 0.9, 32, 32)\n",
    "    \n",
    "    train_X = np.concatenate((mask, train_X*mask), axis=1)\n",
    "    \n",
    "    test_X = inframes[1300:,:,window_off_x:window_off_x+windowsize,window_off_y:window_off_y+windowsize]\n",
    "    test_y = get_middle_slice(test_X)\n",
    "    test_mask_shape = list(test_X.shape)\n",
    "    test_mask_shape[1] = 1\n",
    "    if (i%2==0):\n",
    "        test_mask = tile_batch_mask(test_mask_shape, 0.80, 16, 16)\n",
    "    else:\n",
    "        test_mask = tile_batch_mask(test_mask_shape, 0.90, 32, 32)\n",
    "    \n",
    "    \n",
    "    \n",
    "    test_X = np.concatenate((test_mask, test_X*test_mask), axis=1)\n",
    "    train_iter = mx.io.NDArrayIter({'data' : train_X}, { 'y' : train_y }, shuffle=True, batch_size=batch_size)\n",
    "    test_iter = mx.io.NDArrayIter({'data' : test_X}, { 'y' : test_y}, shuffle=True, batch_size=batch_size)\n",
    "    print \"New Windowed Batch %i\" % (i)\n",
    "    model.fit(train_iter,\n",
    "          eval_data=test_iter,\n",
    "          eval_metric=\"mae\",\n",
    "          batch_end_callback=mx.callback.Speedometer(batch_size))\n",
    "    if (i % 5==4):\n",
    "        model.save('dilated-autoencoder2_%d' % (i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "size = 0\n",
    "for k in model.arg_params:\n",
    "    size += np.prod(model.arg_params[k].shape)\n",
    "print \"Model size: \",size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mx.viz.plot_network(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out.list_arguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arg_shape, out_shape, aux_shape = out.infer_shape(X=(10, 3, 640,480), y=(10,3,270,110))\n",
    "dict(zip(net.list_arguments(), arg_shape))\n",
    "size = 0\n",
    "for s in arg_shape:\n",
    "    print s\n",
    "    size += np.prod(s)\n",
    "print \"Total parameter size=%d MB, total temp size=%d MB\" % (size / (1024*1024), 640*480*1000*8 / (1024*1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net.list_arguments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note\n",
    "\n",
    "\n",
    " * Important Paper about Dilated Convolution: http://arxiv.org/pdf/1511.07122v1.pdf\n",
    "\n",
    " * Deep Probabilistic Inference Models http://gitxiv.com/posts/oRw692PEooNcwh9Qh/neural-variational-inference-for-text-processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Keras Models ##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten, Reshape, Permute\n",
    "from keras.layers.advanced_activations import ThresholdedReLU\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.convolutional import Convolution2D, ZeroPadding2D\n",
    "from keras.datasets import imdb\n",
    "from keras.optimizers import SGD\n",
    "from keras.regularizers import l1,l2,l1l2, ActivityRegularizer, activity_l1\n",
    "from keras import backend as K\n",
    "import keras.layers.convolutional as kconv\n",
    "import tensorflow as tf\n",
    "import tensorflow as tf\n",
    "from keras.layers import MaskedLayer\n",
    "import keras.backend as K\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "_FLOATX = K.floatx()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'Build model...X'\n",
    "\n",
    "num_feature_detectors=12*12*3\n",
    "tile_size=12\n",
    "receptive_field_size=16\n",
    "model = Sequential()\n",
    "model.add(Dropout(0.001, input_shape=ichunkshape[1:]))\n",
    "\n",
    "input_features = Convolution2D( name='encode_tiled_features', \n",
    "                        nb_filter=num_feature_detectors, nb_row=receptive_field_size,nb_col=receptive_field_size, \n",
    "                        subsample=(tile_size,tile_size), \n",
    "                        border_mode='valid', trainable=True,\n",
    "                        dim_ordering='tf' )\n",
    "\n",
    "\n",
    "print np.prod(ichunkshape[1:])\n",
    "model.add(input_features)\n",
    "\n",
    "print input_features.output_shape \n",
    "\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "decoder = Convolution2D( name='decode_tiled_features', \n",
    "                        nb_filter=tile_size*tile_size*3, nb_row=1,nb_col=1, subsample=(1,1),\n",
    "                        border_mode='same', trainable=True,\n",
    "                        dim_ordering='tf')\n",
    "\n",
    "model.add(decoder)\n",
    "model.add(Reshape(tuple(list(decoder.output_shape[1:3]) + [tile_size, tile_size, 3])))\n",
    "print model.output_shape\n",
    "model.add(Permute((1,3,2,4,5)))\n",
    "\n",
    "print model.output_shape\n",
    "model.add(Reshape((model.output_shape[1]*model.output_shape[2],model.output_shape[3]*model.output_shape[4],model.output_shape[5])))\n",
    "\n",
    "model.add(ZeroPadding2D(((ichunkshape[1]-model.output_shape[1])/2, (ichunkshape[2]-model.output_shape[2])/2), \n",
    "                        dim_ordering='tf'))\n",
    "\n",
    "print model.output_shape\n",
    "def mean_abs_error_all(y_true, y_pred):\n",
    "    return K.mean(K.abs(y_pred - y_true), axis=None)\n",
    "\n",
    "\n",
    "\n",
    "print model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=mean_abs_error_all, class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def data_generator(batchsize):\n",
    "    for i in range(10):\n",
    "        for j in permutation(1300):\n",
    "            bi = inframesmem[j:(j+batchsize),:,:,:]\n",
    "\n",
    "            yield bi,  bi\n",
    "\n",
    "for i in range(1):\n",
    "    print \"Over-Epoch %i\" % (i)\n",
    "    model.fit_generator(data_generator(40), validation_data=(inframes[1400:1430], inframes[1400:1430]),\n",
    "              show_accuracy=False, nb_epoch=1, samples_per_epoch=500, nb_worker=1)\n",
    "\n",
    "model.save_weights('model1.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def data_generator(batchsize):\n",
    "    for i in range(10):\n",
    "        for j in permutation(1300):\n",
    "            bi = inframesm[j:(j+batchsize),:,:,:]\n",
    "            yield bi,  bi\n",
    "\n",
    "for i in range(1):\n",
    "    print \"Over-Epoch %i\" % (i)\n",
    "    model.fit_generator(data_generator(4), validation_data=(inframes[1400:1430], inframes[1400:1430]),\n",
    "              show_accuracy=False, nb_epoch=5, samples_per_epoch=400, nb_worker=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'Build model...X'\n",
    "\n",
    "num_feature_detectors=16*16*4\n",
    "tile_size=16\n",
    "receptive_field_size=24\n",
    "model = Sequential()\n",
    "model.add(Dropout(0.1, input_shape=ichunkshape[1:]))\n",
    "\n",
    "input_features = Convolution2D( name='encode_tiled_features', \n",
    "                        nb_filter=num_feature_detectors, nb_row=receptive_field_size,nb_col=receptive_field_size, \n",
    "                        subsample=(tile_size,tile_size), \n",
    "                        border_mode='valid', trainable=True,\n",
    "                        dim_ordering='tf', activity_regularizer=activity_l1(0.0000005))\n",
    "\n",
    "\n",
    "model.add(input_features)\n",
    "model.add(PReLU())\n",
    "\n",
    "decoder = Convolution2D( name='decode_tiled_features', \n",
    "                        nb_filter=tile_size*tile_size*3, nb_row=1,nb_col=1, subsample=(1,1),\n",
    "                        border_mode='same', trainable=True,\n",
    "                        dim_ordering='tf')\n",
    "\n",
    "model.add(decoder)\n",
    "model.add(Reshape(tuple(list(decoder.output_shape[1:3]) + [tile_size, tile_size, 3])))\n",
    "print model.output_shape\n",
    "model.add(Permute((1,3,2,4,5)))\n",
    "\n",
    "print model.output_shape\n",
    "model.add(Reshape((model.output_shape[1]*model.output_shape[2],model.output_shape[3]*model.output_shape[4],model.output_shape[5])))\n",
    "\n",
    "model.add(ZeroPadding2D(((ichunkshape[1]-model.output_shape[1])/2, (ichunkshape[2]-model.output_shape[2])/2), \n",
    "                        dim_ordering='tf'))\n",
    "\n",
    "print model.output_shape\n",
    "def mean_abs_error_all(y_true, y_pred):\n",
    "    return K.mean(K.abs(y_pred - y_true), axis=None)\n",
    "\n",
    "\n",
    "\n",
    "print model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=mean_abs_error_all, class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def data_generator(batchsize):\n",
    "    for i in range(10):\n",
    "        perm = permutation(1300)\n",
    "        for i in range(len(perm)//batchsize):\n",
    "            bi = inframesmem[perm[i*batchsize:(i+1)*batchsize],:,:,:]\n",
    "            yield bi,  bi\n",
    "\n",
    "for i in range(1):\n",
    "    print \"Over-Epoch %i\" % (i)\n",
    "    model.fit_generator(data_generator(30), validation_data=(inframes[1400:1430], inframes[1400:1430]),\n",
    "              show_accuracy=False, nb_epoch=5, samples_per_epoch=400, nb_worker=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'Build model...X'\n",
    "\n",
    "num_feature_detectors=12*12*3\n",
    "tile_size=12\n",
    "receptive_field_size=16\n",
    "model = Sequential()\n",
    "model.add(Dropout(0.1, input_shape=ichunkshape[1:]))\n",
    "\n",
    "enc1 = Convolution2D( name='enc1', \n",
    "                        nb_filter=num_feature_detectors, nb_row=receptive_field_size,nb_col=receptive_field_size, \n",
    "                        subsample=(tile_size,tile_size), \n",
    "                        border_mode='valid', trainable=True,\n",
    "                        dim_ordering='tf', activity_regularizer=activity_l1(0.0000005))\n",
    "\n",
    "\n",
    "model.add(enc1)\n",
    "model.add(PReLU())\n",
    "model.add(Dropout(0.1))\n",
    "# ---------------\n",
    "tile_size2=2\n",
    "num_feature_detectors2=tile_size2*tile_size2*num_feature_detectors \n",
    "receptive_field_size2=2\n",
    "\n",
    "enc2 = Convolution2D( name='enc2', \n",
    "                        nb_filter=num_feature_detectors2, nb_row=receptive_field_size2,nb_col=receptive_field_size2, \n",
    "                        subsample=(tile_size2,tile_size2), \n",
    "                        border_mode='valid', trainable=True,\n",
    "                        dim_ordering='tf', activity_regularizer=activity_l1(0.0))\n",
    "\n",
    "\n",
    "model.add(enc2)\n",
    "model.add(PReLU())\n",
    "\n",
    "# --------------------\n",
    "\n",
    "dec2 = Convolution2D( name='dec2', \n",
    "                        nb_filter=tile_size2*tile_size2*num_feature_detectors, nb_row=1,nb_col=1, subsample=(1,1),\n",
    "                        border_mode='valid', trainable=True,\n",
    "                        dim_ordering='tf')\n",
    "\n",
    "model.add(dec2)\n",
    "# We need to reshape and reorder dimensions, so we can, at least in theory, do symmetric, layer-wise training...\n",
    "newshape2 = tuple(list(dec2.output_shape[1:3])+ [tile_size2, tile_size2, num_feature_detectors])\n",
    "model.add(Reshape(newshape2))\n",
    "model.add(Permute((1,3,2,4,5)))\n",
    "blockshape2 = (model.output_shape[1]*model.output_shape[2], model.output_shape[3]*model.output_shape[4], model.output_shape[5])\n",
    "\n",
    "model.add(Reshape(blockshape2))\n",
    "\n",
    "# --------------------\n",
    "\n",
    "dec1 = Convolution2D( name='dec1', \n",
    "                        nb_filter=tile_size*tile_size*3, nb_row=1,nb_col=1, subsample=(1,1),\n",
    "                        border_mode='same', trainable=True,\n",
    "                        dim_ordering='tf')\n",
    "model.add(dec1)\n",
    "newshape1 = tuple(list(dec1.output_shape[1:3])+ [tile_size, tile_size, 3])\n",
    "model.add(Reshape(newshape1))\n",
    "model.add(Permute((1,3,2,4,5)))\n",
    "\n",
    "blockshape1 = (model.output_shape[1]*model.output_shape[2],model.output_shape[3]*model.output_shape[4], model.output_shape[5])\n",
    "\n",
    "model.add(Reshape(blockshape1))\n",
    "\n",
    "model.add(ZeroPadding2D(((ichunkshape[1]-model.output_shape[1])/2, (ichunkshape[2]-model.output_shape[2])/2), \n",
    "                        dim_ordering='tf'))\n",
    "\n",
    "# --------------------\n",
    "\n",
    "print model.output_shape\n",
    "def mean_abs_error_all(y_true, y_pred):\n",
    "    return K.mean(K.abs(y_pred - y_true), axis=None)\n",
    "\n",
    "\n",
    "\n",
    "print model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=mean_abs_error_all, class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from theano import function, config, shared, sandbox\n",
    "import theano.tensor as T\n",
    "import numpy\n",
    "import time\n",
    "\n",
    "vlen = 10 * 30 * 768  # 10 x #cores x # threads per core\n",
    "iters = 1000\n",
    "\n",
    "rng = numpy.random.RandomState(22)\n",
    "x = shared(numpy.asarray(rng.rand(vlen), config.floatX))\n",
    "f = function([], T.exp(x))\n",
    "print(f.maker.fgraph.toposort())\n",
    "t0 = time.time()\n",
    "for i in range(iters):\n",
    "    r = f()\n",
    "t1 = time.time()\n",
    "print(\"Looping %d times took %f seconds\" % (iters, t1 - t0))\n",
    "print(\"Result is %s\" % (r,))\n",
    "if numpy.any([isinstance(x.op, T.Elemwise) for x in f.maker.fgraph.toposort()]):\n",
    "    print('Used the cpu')\n",
    "else:\n",
    "    print('Used the gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def data_generator(batchsize):\n",
    "    while True:\n",
    "        perm = permutation(1400)\n",
    "        for i in range(len(perm)//batchsize):\n",
    "            bi = inframesmem[perm[i*batchsize:(i+1)*batchsize],:,:,:]\n",
    "            yield bi,  bi\n",
    "\n",
    "for i in range(1):\n",
    "    print \"Over-Epoch %i\" % (i)\n",
    "    model.fit_generator(data_generator(40), validation_data=(inframes[1400:1480], inframes[1400:1480]),\n",
    "              show_accuracy=False, nb_epoch=10, samples_per_epoch=500, nb_worker=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('sparse_autoencoder_4layers.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Visualizing the reconstructed video ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!mkdir imageseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!rm imageseries/*.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask = tile_batch_mask((1,1,360, 640), 0.8, 4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "j = 0\n",
    "c = 0\n",
    "\n",
    "for i in permuted_indices:    \n",
    "    #print np.sum(hsvimg-hsvimg2)\n",
    "    fframe = inframes[i,:,:,:] # np.transpose(inframes[i,:,:,:], [1,2,0])\n",
    "    fframe = fframe[np.newaxis,:,:,:]\n",
    "    mfframe = np.concatenate((mask, fframe*mask), axis=1)\n",
    "    bgi =  mx.io.NDArrayIter({'data' : mfframe}, batch_size=1)\n",
    "    \n",
    "    pframe = model.predict(bgi, num_batch=1)[0]\n",
    "    pframe = np.clip(pframe, 0.0, 1.0, pframe)\n",
    "    pframe = (pframe * 255.0).astype(np.uint8)\n",
    "    piframe = np.transpose(pframe, [1,2,0])\n",
    "    bgrimg = cv2.cvtColor(piframe, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    j+=1\n",
    "    c+=1\n",
    "    cv2.imwrite(\"imageseries/reconstruction1_%05d.jpg\" % (c), bgrimg)\n",
    "    if (c>400):\n",
    "        break\n",
    "    if (j % 10==0):\n",
    "        print \"frame %d\" % (c)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "display(Image('imageseries/reconstruction1_00002.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!rm imageseries/*.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!rm videos/Chimpanzees1_reconstructed3.mp4\n",
    "!ffmpeg -i imageseries/reconstruction1_%05d.jpg -c:v libx264 -b:v 400k -maxrate:v 500k -bufsize 1000k -r 10 -preset medium videos/Chimpanzees1_reconstructed3.mp4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!ls -hs imageseries/recons*.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display(Image('imageseries/reconstruction1_00052.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "link_video('videos/Chimpanzees1_reconstructed3.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "display(FileLink('videos/Chimpanzees1_reconstructed3.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "link_video('videos/Chimpanzees1_reconstructed2.mp4')\n",
    "#link_video('videos/Chimpanzees1_reconstructed2.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "link_video('videos/Chimpanzees1.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display(FileLink('videos/Chimpanzees1_reconstructed2.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class array(object) :\n",
    "    \"\"\"Simple Array object that support autodiff.\"\"\"\n",
    "    def __init__(self, value, name=None):\n",
    "        self.value = value\n",
    "        if name:\n",
    "            self.grad = lambda g : {name : g}\n",
    "\n",
    "    def __add__(self, other):dilate\n",
    "        assert isinstance(other, int)\n",
    "        ret = array(self.value + other)\n",
    "        ret.grad = lambda g : self.grad(g)\n",
    "        return ret\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        assert isinstance(other, array)\n",
    "        ret = array(self.value * other.value)\n",
    "        def grad(g):\n",
    "            x = self.grad(g * other.value)\n",
    "            x.update(other.grad(g * self.value))\n",
    "            return x\n",
    "        ret.grad = grad\n",
    "        return ret\n",
    "\n",
    "# some examples\n",
    "a = array(1, 'a')\n",
    "b = array(2, 'b')\n",
    "c = b * a\n",
    "d = c + 1\n",
    "print d.value\n",
    "print d.grad(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(b*a).grad(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
