{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install ffmpeg and libavcodec-dev (plus related stuff) from\n",
    "https://launchpad.net/~mc3man/+archive/ubuntu/trusty-media\n",
    "\n",
    "Install OpenCV using the instructions from \n",
    "http://www.pyimagesearch.com/2015/06/22/install-opencv-3-0-and-python-2-7-on-ubuntu/\n",
    "\n",
    "In my case I had a build error related to missing CUDA libs, so the build command I used was\n",
    "\n",
    "    cmake -D CMAKE_BUILD_TYPE=RELEASE \\\n",
    "            -D CMAKE_INSTALL_PREFIX=/usr/local \\\n",
    "            -D INSTALL_C_EXAMPLES=OFF \\\n",
    "            -D INSTALL_PYTHON_EXAMPLES=ON \\\n",
    "            -D \"OPENCV_EXTRA_MODULES_PATH=../../opencv_contrib/modules\" \\\n",
    "            -D BUILD_EXAMPLES=ON \\\n",
    "            -D WITH_CUDA=OFF ..\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied (use --upgrade to upgrade): pytube in /usr/local/lib/python2.7/dist-packages\r\n",
      "Cleaning up...\r\n"
     ]
    }
   ],
   "source": [
    "!sudo pip install pytube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reset GPU\n",
    "#!sudo rmmod nvidia_uvm\n",
    "#!sudo rmmod nvidia\n",
    "#!sudo insmod /lib/modules/3.13.0-77-generic/kernel/drivers/video/nvidia.ko\n",
    "#!sudo insmod /lib/modules/3.13.0-77-generic/kernel/drivers/video/nvidia-uvm.ko\n",
    "#!echo \"OK\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory 'videos': File exists\n",
      "mkdir: cannot create directory 'imageseries': File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir videos\n",
    "!mkdir imageseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capoeira_Girl.mp4   Chimpanzees1.mp4\t\t     Solar-System.mp4\r\n",
      "Capoeira_Movie.mp4  Chimpanzees1_reconstructed2.mp4\r\n",
      "Chimpanzees.mp4     Chimpanzees1_reconstructed3.mp4\r\n"
     ]
    }
   ],
   "source": [
    "!ls videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "videos = {\n",
    "    'Solar-System' : 'https://www.youtube.com/watch?v=jvhM4tANYDg',\n",
    "    'Chimpanzees' : 'https://www.youtube.com/watch?v=yim23IFJOyQ',\n",
    "    'Capoeira_Girl' : 'https://www.youtube.com/watch?v=vwG7JwXtUSI',\n",
    "    'Capoeira_Movie' : 'https://www.youtube.com/watch?v=6-DYrZXj3W4'\n",
    "}\n",
    "download = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "current_movie = 'Chimpanzees.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if (download):\n",
    "\n",
    "    from pytube import YouTube\n",
    "\n",
    "    # not necessary, just for demo purposes.\n",
    "    from pprint import pprint\n",
    "    for filename in videos.keys():\n",
    "        url = videos[filename]\n",
    "        yt = YouTube(url)\n",
    "        print \"Downloading %s from %s\" % (filename, url)\n",
    "        yt.set_filename(filename)\n",
    "        video = yt.get('mp4', '360p')\n",
    "        video.download('./videos/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now let's try to read this using our fresh opencv build.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML, FileLink, display, clear_output\n",
    "from base64 import b64encode\n",
    "def link_video(path):\n",
    "    src = FileLink(path)\n",
    "    video_tag = '<video controls alt=\"test\" src=\"%s\">' % (path)\n",
    "    \n",
    "    display(HTML(data=video_tag))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could read 1490 frames of shape (360, 640, 3) and dtype dtype('uint8')\n"
     ]
    }
   ],
   "source": [
    "vc = cv2.VideoCapture('videos/%s' % current_movie)\n",
    "frames = 0\n",
    "shape = None\n",
    "dtype = None\n",
    "while (True):\n",
    "    ret, img = vc.read()\n",
    "    # img should be an numpy ndarray of shape (width, heigth, channels)\n",
    "    if (not ret):\n",
    "        break\n",
    "    if (shape is None):\n",
    "        shape = img.shape\n",
    "    if (dtype is None):\n",
    "        dtype = img.dtype\n",
    "    if (frames>=15000):\n",
    "        break\n",
    "    frames+=1\n",
    "    \n",
    "    \n",
    "print \"Could read %d frames of shape %r and dtype %r\" % (frames, shape, dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import h5py\n",
    "\n",
    "#h5f = h5py.File('videos/Chimpanzees1_7.hdf5',driver='core', backing_store=True)\n",
    "#h5f = h5py.File('/tmp/Chimpanzees1_7.hdf5')\n",
    "#h5g = h5f.create_group('input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rshape = [ shape[2],shape[0], shape[1] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ishape = tuple([ frames ] + list(rshape))\n",
    "ichunkshape = tuple([ 1 ] + list(rshape))\n",
    "imaxshape = tuple([ None ] + list(rshape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import permutation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#inframes = h5g.create_dataset('raw_hsl_frames', \n",
    "#                             shape=ishape, dtype=np.float32, \n",
    "#                             chunks=ichunkshape, maxshape=imaxshape,\n",
    "#                             fletcher32=True, fillvalue=0)\n",
    "#\n",
    "inframes = np.zeros(shape=ishape, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nframes = frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1490"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1490, 3, 360, 640)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inframes.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 759,  257, 1234, ..., 1482, 1313,  993])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permuted_indices = permutation(range(frames))\n",
    "\n",
    "permuted_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1490"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame #300\n",
      "Frame #600\n",
      "Frame #900\n",
      "Frame #1200\n",
      "Read 1490 frames\n"
     ]
    }
   ],
   "source": [
    "vc = cv2.VideoCapture('videos/%s' % current_movie)\n",
    "frames = 0\n",
    "shape = None\n",
    "dtype = None\n",
    "for f in range(nframes):\n",
    "    ret, img = vc.read()\n",
    "    if (not ret):\n",
    "        break\n",
    "    hsvimg = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    \n",
    "    hsvimgf = hsvimg.astype(np.float32) / 255.0\n",
    "    hsvimgf = hsvimgf.swapaxes(2,0).swapaxes(1,2)\n",
    "    # img should be an numpy ndarray of shape (width, heigth, channels)\n",
    "    inframes[permuted_indices[frames],:,:,:] = hsvimgf\n",
    "    \n",
    "    #hsvimg2 = (inframes[permuted_indices[frames],:,:,:] * 255.0).astype(np.uint8)\n",
    "    \n",
    "    #print np.sum(hsvimg-hsvimg2)\n",
    "    #bgrimg = cv2.cvtColor(hsvimg2, cv2.COLOR_HSV2BGR)\n",
    "    #print np.sum(img-bgrimg)\n",
    "    \n",
    "    #cv2.imwrite(\"videos/recoded1_%05d.png\" % (frames), bgrimg)\n",
    "    \n",
    "    frames+=1\n",
    "    if (frames % 300==0):\n",
    "        print \"Frame #%d\" % (frames)\n",
    "print \"Read %d frames\" % (frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#inframesmem = np.array(inframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!rm videos/Chimpanzees1_recoded.mp4\n",
    "#!ffmpeg -i imageseries/Chimpanzees1_%05d.png -c:v libx264 -b:v 400k -vf format=yuv420p -maxrate:v 500k -bufsize 1000k  -r 10 -preset medium videos/Chimpanzees1_recoded.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#link_video('videos/Chimpanzees1_recoded.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "from glob import glob\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy.lib.stride_tricks import as_strided\n",
    "\n",
    "def tile_array(a, b1, b2):\n",
    "    r, c = a.shape\n",
    "    rs, cs = a.strides\n",
    "    x = as_strided(a, (r, b1, c, b2), (rs, 0, cs, 0))\n",
    "    return x.reshape(r*b1, c*b2)\n",
    "\n",
    "def tile_batch_mask(shape, p, tile_x, tile_y):\n",
    "    target = np.ones(shape=shape, dtype=np.float32)\n",
    "    assert(shape[1]==1)\n",
    "    for i in range(target.shape[0]):\n",
    "        \n",
    "        rnd_shape = (shape[2] / tile_x, shape[3] / tile_y)\n",
    "        rnd = (np.random.random(rnd_shape)<=p).astype(np.float32)\n",
    "        tiled = tile_array(rnd, tile_x, tile_y)\n",
    "        target[i,0,:,:] = tiled\n",
    "    return target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MXNet ##\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06:30:00 DEBUG:debug\n",
      "06:30:00 INFO:info\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "reload(logging)\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s:%(message)s', level=logging.DEBUG, datefmt='%I:%M:%S')\n",
    "logging.debug(\"debug\")\n",
    "logging.info(\"info\")\n",
    "\n",
    "import os\n",
    "# Comment this out, once it all works\n",
    "os.environ['MXNET_ENGINE_TYPE']='NaiveEngine'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import mxnet.io as mxio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_network(dilate_layers=4, squeeze_factor = 0.5, mult_factor=4, squeeze_constant=16, \n",
    "                   conv_factor=24, conv_constant=32, intermediate_dropout=0.05, \n",
    "                   final_dropout=0.2, final_num_features=1024):\n",
    "\n",
    "    data = mx.symbol.Variable('data')\n",
    "    y = mx.symbol.Variable('y')\n",
    "\n",
    "    net = data\n",
    "    dil = 1\n",
    "    for d in range(1,dilate_layers+1):\n",
    "        \n",
    "        #net = mx.symbol.Convolution(net, kernel=(3,3), num_filter=int(d*squeeze_factor*mult_factor)+squeeze_constant, name='squeeze_pre_%d' % (d), workspace=200)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #netA = mx.symbol.Convolution(net, kernel=(3,3), num_filter=d*conv_factor/2+conv_constant, \n",
    "        #                            dilate=(dil,dil), name='convA%d' % (d), workspace=200)\n",
    "        \n",
    "        #netB = mx.symbol.Convolution(net, kernel=(1,1), num_filter=d*conv_factor/2+conv_constant, \n",
    "        #                            dilate=(dil,dil), name='convB%d' % (d), workspace=200)\n",
    "\n",
    "        # We need to crop net1, since it can be larger than net2 \n",
    "        #netB = mx.symbol.Crop(netB, netA, num_args=2, center_crop=True)  \n",
    "\n",
    "        #net = mx.symbol.Concat(netA,netB)\n",
    "\n",
    "        #net = mx.symbol.LeakyReLU(net, act_type='prelu')\n",
    "        #print net.infer_shape(data=(10,4,64,64))\n",
    "        #if (intermediate_dropout>0.0):\n",
    "            #net = mx.symbol.DropoutAllChannels(net, p=intermediate_dropout)\n",
    "        \n",
    "        #net = mx.symbol.Convolution(net, kernel=(1,1), num_filter=(d+1)*mult_factor+squeeze_constant, name='squeeze_dummy_%d' % (d), workspace=200)\n",
    "        #print \"PX1: %d\" % ( int(d*squeeze_factor*mult_factor)+squeeze_constant)\n",
    "        #print \"PX1: %d\" % ( (d+1)*mult_factor+squeeze_constant)\n",
    "        #print net.infer_shape(data=(10,4,64,64))\n",
    "        #net = mx.symbol.Convolution(net, kernel=(1,1),  num_filter=(d+1)*mult_factor+squeeze_constant, name='squeeze_pre_%d' % (d), workspace=200)\n",
    "        \n",
    "        net = mx.symbol.Convolution(net, kernel=(3,3), dilate=(2,2), num_filter=(d+1)*mult_factor+squeeze_constant, name='squeeze_post_%d' % (d), workspace=200)\n",
    "        net = mx.symbol.LeakyReLU(net, act_type='prelu')\n",
    "        \n",
    "        dil *= 2\n",
    "\n",
    "    net = mx.symbol.Convolution(net, kernel=(3,3), num_filter=final_num_features, name='squeeze_final', workspace=200)\n",
    "    if (final_dropout>0.0):\n",
    "        net = mx.symbol.Dropout(net, p=final_dropout)\n",
    "    net = mx.symbol.Activation(net, act_type='relu')\n",
    "    \n",
    "    net = mx.symbol.Convolution(net, kernel=(3,3), num_filter=3, name='decoder',  workspace=200)\n",
    "    net = mx.symbol.Activation(net, name='final_activation', act_type='relu')\n",
    "    #crop_y = mx.symbol.Crop(y, net, num_args=2, center_crop=True)\n",
    "    out = mx.symbol.MAERegressionOutput(data=net, label=y, name='output_')\n",
    "    return out, net\n",
    "    \n",
    "def get_output_resolution(net, input_shape=(10, 3, 640, 480)):\n",
    "    mshape = list(input_shape)\n",
    "    mshape[1] = 1\n",
    "    return net.infer_shape(data=input_shape, mask=mshape)[-2][0][2:]\n",
    "\n",
    "def get_middle_slice(net, X):\n",
    "    res = get_output_resolution(net, X.shape)\n",
    "    dx = (X.shape[2]-res[0]) // 2\n",
    "    dy = (X.shape[3]-res[1]) // 2\n",
    "    return X[:,:,dx:X.shape[2]-dx,dy:X.shape[3]-dy]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from myio import NDArrayGeneratorIter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def sample_hyperparams(hyperparam_options):\n",
    "    hyperparams = {}\n",
    "    for key in hyperparam_options.keys():\n",
    "        hyperparams[key] = hyperparam_options[key][randint(0, len(hyperparam_options[key]))]\n",
    "    return hyperparams\n",
    "\n",
    "\n",
    "def eval_hyperparams(inframes, hyperparams, num_epoch=10, windowsize=96, batch_size=32, \n",
    "                     keep_prob=0.9, drop_pixel_x=2, drop_pixel_y=2):\n",
    "\n",
    "    hparams = dict(hyperparams)\n",
    "    del hparams['weight_decay']\n",
    "    chunk_size = batch_size*4\n",
    "    print \"Creating Model with params %r\" % (hyperparams)\n",
    "    out, net = create_network(**hparams)\n",
    "    eval_metric = mx.metric.MAE()\n",
    "    \n",
    "    allgpus = [ mx.gpu(i) for i in range(2)]\n",
    "    allcpus = [ mx.cpu(i) for i in range(12)]\n",
    "    optimizer = myopt.MyAdaGrad(learning_rate=0.01, wd=hyperparams['weight_decay'])\n",
    "    model = mxmodel.FeedForward(ctx=allgpus, symbol=out, \n",
    "                                num_epoch=num_epoch, optimizer=optimizer)\n",
    "    \n",
    "    def training_generator():\n",
    "        while True:\n",
    "            window_off_x =  np.random.randint(0, inframes.shape[2]-windowsize)\n",
    "            window_off_y = np.random.randint(0, inframes.shape[3]-windowsize)\n",
    "            start = np.random.randint(0, inframes.shape[0]-400-chunk_size)\n",
    "            train_X = inframes[start:start+chunk_size,:,window_off_x:window_off_x+windowsize,window_off_y:window_off_y+windowsize]\n",
    "            train_y = get_middle_slice(net, train_X)\n",
    "            mask_shape = list(train_X.shape)\n",
    "            mask_shape[1] = 1\n",
    "            mask = tile_batch_mask(mask_shape, keep_prob, drop_pixel_x, drop_pixel_y)\n",
    "\n",
    "            #train_X = np.concatenate((mask, train_X*mask), axis=1)\n",
    "            yield {'data' : train_X}, { 'y' : train_y}\n",
    "\n",
    "    def test_generator():\n",
    "        while True:\n",
    "            window_off_x =  np.random.randint(0, inframes.shape[2]-windowsize)\n",
    "            window_off_y = np.random.randint(0, inframes.shape[3]-windowsize)\n",
    "            test_X = inframes[inframes.shape[0]-400:,:,window_off_x:window_off_x+windowsize,window_off_y:window_off_y+windowsize]\n",
    "            test_y = get_middle_slice(net, test_X)\n",
    "            test_mask_shape = list(test_X.shape)\n",
    "            test_mask_shape[1] = 1\n",
    "            mask = tile_batch_mask(test_mask_shape, keep_prob, drop_pixel_x, drop_pixel_y)\n",
    "\n",
    "            #test_X = np.concatenate((test_mask, test_X*test_mask), axis=1)\n",
    "            yield {'data' : test_X}, { 'y' : test_y}\n",
    "            \n",
    "   \n",
    "        #test_X = np.concatenate((test_mask, test_X*test_mask), axis=1)\n",
    "    train_iter = NDArrayGeneratorIter(training_generator(), 2, shuffle=True, batch_size=batch_size, last_batch_handle='discard')\n",
    "    test_iter = NDArrayGeneratorIter(training_generator(), 1, shuffle=True, batch_size=batch_size, last_batch_handle='discard')\n",
    "    test_iter.reset()\n",
    "    model.fit(train_iter,\n",
    "              eval_data=test_iter,\n",
    "              eval_metric=eval_metric,\n",
    "              batch_end_callback=mx.callback.Speedometer(batch_size, 4))\n",
    "        \n",
    "    return model, hyperparams, eval_metric.get()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import traceback\n",
    "from IPython.display import clear_output,display\n",
    "from numpy.random import randint\n",
    "import mymodel as mxmodel\n",
    "import myopt as myopt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logger.level = logging.INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(FeedForward(allow_extra_params=False,\n",
       "        arg_params={'squeeze_final_bias': <mxnet.ndarray.NDArray object at 0x2b5dbdef0ad0>, 'decoder_weight': <mxnet.ndarray.NDArray object at 0x2b5dbdef0b10>, 'decoder_bias': <mxnet.ndarray.NDArray object at 0x2b5dbdef0a10>, 'squeeze_post_1_bias': <mxnet.ndarray.NDArray object at 0x2b5dbdef0f10>, 'leakyrel...bject at 0x2b5dbdef0190>, 'squeeze_post_1_weight': <mxnet.ndarray.NDArray object at 0x2b5dbdef0690>},\n",
       "        aux_params={}, begin_epoch=0, ctx=[gpu(0)], epoch_size=None,\n",
       "        initializer=<mxnet.initializer.Uniform object at 0x2b5dbdc31dd0>,\n",
       "        num_epoch=20, numpy_batch_size=128,\n",
       "        optimizer=<myopt.MyAdaGrad object at 0x2b5dc4998410>,\n",
       "        symbol=<mxnet.symbol.Symbol object at 0x2b5dc4998110>),\n",
       "  {'conv_constant': 8,\n",
       "   'conv_factor': 16,\n",
       "   'dilate_layers': 1,\n",
       "   'final_dropout': 0.1,\n",
       "   'final_num_features': 160,\n",
       "   'intermediate_dropout': 0.0,\n",
       "   'mult_factor': 2,\n",
       "   'squeeze_constant': 8,\n",
       "   'squeeze_factor': 0.5,\n",
       "   'weight_decay': 0.0},\n",
       "  ('mae', 0.045969190075993538)),\n",
       " (FeedForward(allow_extra_params=False,\n",
       "        arg_params={'squeeze_final_bias': <mxnet.ndarray.NDArray object at 0x2b5dc495f450>, 'decoder_weight': <mxnet.ndarray.NDArray object at 0x2b5dc495f490>, 'decoder_bias': <mxnet.ndarray.NDArray object at 0x2b5dbdf48e50>, 'squeeze_post_1_bias': <mxnet.ndarray.NDArray object at 0x2b5dc495f9d0>, 'squeeze_...bject at 0x2b5dc495f350>, 'squeeze_post_1_weight': <mxnet.ndarray.NDArray object at 0x2b5dc7fcdfd0>},\n",
       "        aux_params={}, begin_epoch=0, ctx=[gpu(0)], epoch_size=None,\n",
       "        initializer=<mxnet.initializer.Uniform object at 0x2b5dbdc31dd0>,\n",
       "        num_epoch=20, numpy_batch_size=128,\n",
       "        optimizer=<myopt.MyAdaGrad object at 0x2b5dc4998490>,\n",
       "        symbol=<mxnet.symbol.Symbol object at 0x2b5dbdef0750>),\n",
       "  {'conv_constant': 8,\n",
       "   'conv_factor': 16,\n",
       "   'dilate_layers': 1,\n",
       "   'final_dropout': 0.1,\n",
       "   'final_num_features': 160,\n",
       "   'intermediate_dropout': 0.0,\n",
       "   'mult_factor': 2,\n",
       "   'squeeze_constant': 8,\n",
       "   'squeeze_factor': 1.0,\n",
       "   'weight_decay': 0.0},\n",
       "  ('mae', 0.029254060937091708)),\n",
       " (FeedForward(allow_extra_params=False,\n",
       "        arg_params={'squeeze_final_bias': <mxnet.ndarray.NDArray object at 0x2b5dbdf488d0>, 'squeeze_post_1_weight': <mxnet.ndarray.NDArray object at 0x2b5dbdf54710>, 'decoder_bias': <mxnet.ndarray.NDArray object at 0x2b5dbdf48250>, 'squeeze_post_1_bias': <mxnet.ndarray.NDArray object at 0x2b5dbdf54950>, 'l...Array object at 0x2b5dbdf48110>, 'decoder_weight': <mxnet.ndarray.NDArray object at 0x2b5dbdf48610>},\n",
       "        aux_params={}, begin_epoch=0, ctx=[gpu(0)], epoch_size=None,\n",
       "        initializer=<mxnet.initializer.Uniform object at 0x2b5dbdc31dd0>,\n",
       "        num_epoch=20, numpy_batch_size=128,\n",
       "        optimizer=<myopt.MyAdaGrad object at 0x2b5dc8015e90>,\n",
       "        symbol=<mxnet.symbol.Symbol object at 0x2b5dc49a3e10>),\n",
       "  {'conv_constant': 8,\n",
       "   'conv_factor': 16,\n",
       "   'dilate_layers': 1,\n",
       "   'final_dropout': 0.1,\n",
       "   'final_num_features': 160,\n",
       "   'intermediate_dropout': 0.0,\n",
       "   'mult_factor': 2,\n",
       "   'squeeze_constant': 8,\n",
       "   'squeeze_factor': 0.5,\n",
       "   'weight_decay': 0.0},\n",
       "  ('mae', 0.057329071220010519)),\n",
       " (FeedForward(allow_extra_params=False,\n",
       "        arg_params={'squeeze_final_bias': <mxnet.ndarray.NDArray object at 0x2b5dc7b6bd50>, 'squeeze_post_1_weight': <mxnet.ndarray.NDArray object at 0x2b5dc7b6bad0>, 'decoder_bias': <mxnet.ndarray.NDArray object at 0x2b5dc7b6bc50>, 'squeeze_post_1_bias': <mxnet.ndarray.NDArray object at 0x2b5dc7b6b610>, 'squeeze_final_weight': <mxnet.ndarray.NDArray object at 0x2b5dc7b6ba90>, 'decoder_weight': <mxnet.ndarray.NDArray object at 0x2b5dc7b6b650>},\n",
       "        aux_params={}, begin_epoch=0, ctx=[gpu(0)], epoch_size=None,\n",
       "        initializer=<mxnet.initializer.Uniform object at 0x2b5dbdc31dd0>,\n",
       "        num_epoch=20, numpy_batch_size=128,\n",
       "        optimizer=<myopt.MyAdaGrad object at 0x2b5dc7ff7f90>,\n",
       "        symbol=<mxnet.symbol.Symbol object at 0x2b5dbdc3af90>),\n",
       "  {'conv_constant': 8,\n",
       "   'conv_factor': 16,\n",
       "   'dilate_layers': 1,\n",
       "   'final_dropout': 0.1,\n",
       "   'final_num_features': 160,\n",
       "   'intermediate_dropout': 0.0,\n",
       "   'mult_factor': 2,\n",
       "   'squeeze_constant': 8,\n",
       "   'squeeze_factor': 0.5,\n",
       "   'weight_decay': 0.0},\n",
       "  ('mae', 0.070235596038401127)),\n",
       " (None,\n",
       "  {'conv_constant': 8,\n",
       "   'conv_factor': 16,\n",
       "   'dilate_layers': 1,\n",
       "   'final_dropout': 0.1,\n",
       "   'final_num_features': 160,\n",
       "   'intermediate_dropout': 0.0,\n",
       "   'mult_factor': 2,\n",
       "   'squeeze_constant': 8,\n",
       "   'squeeze_factor': 0.5,\n",
       "   'weight_decay': 0.0},\n",
       "  None),\n",
       " (None,\n",
       "  {'conv_constant': 8,\n",
       "   'conv_factor': 16,\n",
       "   'dilate_layers': 1,\n",
       "   'final_dropout': 0.1,\n",
       "   'final_num_features': 160,\n",
       "   'intermediate_dropout': 0.0,\n",
       "   'mult_factor': 2,\n",
       "   'squeeze_constant': 8,\n",
       "   'squeeze_factor': 1.0,\n",
       "   'weight_decay': 0.0},\n",
       "  None),\n",
       " (FeedForward(allow_extra_params=False,\n",
       "        arg_params={'squeeze_final_bias': <mxnet.ndarray.NDArray object at 0x2b5dc7b6b710>, 'squeeze_post_1_weight': <mxnet.ndarray.NDArray object at 0x2b5dc7b6bd10>, 'decoder_bias': <mxnet.ndarray.NDArray object at 0x2b5dc7b6bc90>, 'squeeze_post_1_bias': <mxnet.ndarray.NDArray object at 0x2b5dc7b6bc10>, 'squeeze_final_weight': <mxnet.ndarray.NDArray object at 0x2b5dc7b6bf50>, 'decoder_weight': <mxnet.ndarray.NDArray object at 0x2b5dc7b6b750>},\n",
       "        aux_params={}, begin_epoch=0, ctx=[gpu(0), gpu(1)], epoch_size=None,\n",
       "        initializer=<mxnet.initializer.Uniform object at 0x2b5dbdc31dd0>,\n",
       "        num_epoch=20, numpy_batch_size=128,\n",
       "        optimizer=<myopt.MyAdaGrad object at 0x2b5dbdc0f910>,\n",
       "        symbol=<mxnet.symbol.Symbol object at 0x2b5dbdc0f150>),\n",
       "  {'conv_constant': 8,\n",
       "   'conv_factor': 16,\n",
       "   'dilate_layers': 1,\n",
       "   'final_dropout': 0.1,\n",
       "   'final_num_features': 160,\n",
       "   'intermediate_dropout': 0.0,\n",
       "   'mult_factor': 2,\n",
       "   'squeeze_constant': 8,\n",
       "   'squeeze_factor': 1.0,\n",
       "   'weight_decay': 0.0},\n",
       "  ('mae', 0.063215745845809579)),\n",
       " (FeedForward(allow_extra_params=False,\n",
       "        arg_params={'squeeze_final_bias': <mxnet.ndarray.NDArray object at 0x2b5dc7b814d0>, 'squeeze_post_1_weight': <mxnet.ndarray.NDArray object at 0x2b5dc7b78d90>, 'decoder_bias': <mxnet.ndarray.NDArray object at 0x2b5dc7b81610>, 'squeeze_post_1_bias': <mxnet.ndarray.NDArray object at 0x2b5dc7b78c50>, 'squeeze_final_weight': <mxnet.ndarray.NDArray object at 0x2b5dc7b81690>, 'decoder_weight': <mxnet.ndarray.NDArray object at 0x2b5dc7b81210>},\n",
       "        aux_params={}, begin_epoch=0, ctx=[gpu(0), gpu(1)], epoch_size=None,\n",
       "        initializer=<mxnet.initializer.Uniform object at 0x2b5dbdc31dd0>,\n",
       "        num_epoch=20, numpy_batch_size=128,\n",
       "        optimizer=<myopt.MyAdaGrad object at 0x2b5dc8015fd0>,\n",
       "        symbol=<mxnet.symbol.Symbol object at 0x2b5dbdec9bd0>),\n",
       "  {'conv_constant': 8,\n",
       "   'conv_factor': 16,\n",
       "   'dilate_layers': 1,\n",
       "   'final_dropout': 0.1,\n",
       "   'final_num_features': 160,\n",
       "   'intermediate_dropout': 0.0,\n",
       "   'mult_factor': 2,\n",
       "   'squeeze_constant': 8,\n",
       "   'squeeze_factor': 1.0,\n",
       "   'weight_decay': 0.0},\n",
       "  ('mae', 0.052066597621887922)),\n",
       " (FeedForward(allow_extra_params=False,\n",
       "        arg_params={'squeeze_final_bias': <mxnet.ndarray.NDArray object at 0x2b5dc49ad310>, 'decoder_bias': <mxnet.ndarray.NDArray object at 0x2b5dc49ad910>, 'decoder_weight': <mxnet.ndarray.NDArray object at 0x2b5dc49ada50>, 'squeeze_final_weight': <mxnet.ndarray.NDArray object at 0x2b5dc49ad6d0>, 'squeeze...bject at 0x2b5dc49ade90>, 'squeeze_post_1_weight': <mxnet.ndarray.NDArray object at 0x2b5dc49bd950>},\n",
       "        aux_params={}, begin_epoch=0, ctx=[gpu(0), gpu(1)], epoch_size=None,\n",
       "        initializer=<mxnet.initializer.Uniform object at 0x2b5dbdc31dd0>,\n",
       "        num_epoch=20, numpy_batch_size=128,\n",
       "        optimizer=<myopt.MyAdaGrad object at 0x2b5dbdf48750>,\n",
       "        symbol=<mxnet.symbol.Symbol object at 0x2b5dc7b6b9d0>),\n",
       "  {'conv_constant': 8,\n",
       "   'conv_factor': 16,\n",
       "   'dilate_layers': 1,\n",
       "   'final_dropout': 0.1,\n",
       "   'final_num_features': 160,\n",
       "   'intermediate_dropout': 0.0,\n",
       "   'mult_factor': 2,\n",
       "   'squeeze_constant': 8,\n",
       "   'squeeze_factor': 1.0,\n",
       "   'weight_decay': 0.0},\n",
       "  ('mae', 0.02783476747572422))]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:38:40 INFO:Auto-select kvstore type = local_update_cpu\n",
      "07:38:40 INFO:Start training with [gpu(0), gpu(1)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with {'squeeze_factor': 1.0, 'final_dropout': 0.1, 'intermediate_dropout': 0.0, 'conv_constant': 8, 'squeeze_constant': 8, 'mult_factor': 2, 'final_num_features': 160, 'conv_factor': 16, 'dilate_layers': 1, 'weight_decay': 0.0}\n",
      "Creating Model with params {'squeeze_factor': 1.0, 'final_dropout': 0.1, 'intermediate_dropout': 0.0, 'conv_constant': 8, 'squeeze_constant': 8, 'mult_factor': 2, 'final_num_features': 160, 'conv_factor': 16, 'dilate_layers': 1, 'weight_decay': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:38:41 INFO:Epoch[0] Batch [4]\tSpeed: 309.47 samples/sec\tTrain-mae=0.368319\n",
      "07:38:41 INFO:Epoch[0] Batch [8]\tSpeed: 222.79 samples/sec\tTrain-mae=0.316883\n",
      "07:38:42 INFO:Epoch[0] Batch [12]\tSpeed: 226.76 samples/sec\tTrain-mae=0.201090\n",
      "07:38:42 INFO:Epoch[0] Resetting Data Iterator\n",
      "07:38:42 INFO:Epoch[0] Time cost=1.697\n",
      "07:38:42 INFO:Epoch[0] Validation-mae=0.190086\n",
      "07:38:43 INFO:Epoch[1] Batch [4]\tSpeed: 311.42 samples/sec\tTrain-mae=0.164065\n",
      "07:38:43 INFO:Epoch[1] Batch [8]\tSpeed: 227.46 samples/sec\tTrain-mae=0.161994\n",
      "07:38:44 INFO:Epoch[1] Batch [12]\tSpeed: 226.97 samples/sec\tTrain-mae=0.135071\n",
      "07:38:44 INFO:Epoch[1] Resetting Data Iterator\n",
      "07:38:44 INFO:Epoch[1] Time cost=1.680\n",
      "07:38:44 INFO:Epoch[1] Validation-mae=0.146283\n",
      "07:38:45 INFO:Epoch[2] Batch [4]\tSpeed: 311.99 samples/sec\tTrain-mae=0.131707\n",
      "07:38:45 INFO:Epoch[2] Batch [8]\tSpeed: 227.48 samples/sec\tTrain-mae=0.122608\n",
      "07:38:46 INFO:Epoch[2] Batch [12]\tSpeed: 227.01 samples/sec\tTrain-mae=0.121574\n",
      "07:38:46 INFO:Epoch[2] Resetting Data Iterator\n",
      "07:38:46 INFO:Epoch[2] Time cost=1.679\n",
      "07:38:46 INFO:Epoch[2] Validation-mae=0.085844\n",
      "07:38:46 INFO:Epoch[3] Batch [4]\tSpeed: 312.18 samples/sec\tTrain-mae=0.103094\n",
      "07:38:47 INFO:Epoch[3] Batch [8]\tSpeed: 227.06 samples/sec\tTrain-mae=0.098193\n",
      "07:38:48 INFO:Epoch[3] Batch [12]\tSpeed: 227.44 samples/sec\tTrain-mae=0.096951\n",
      "07:38:48 INFO:Epoch[3] Resetting Data Iterator\n",
      "07:38:48 INFO:Epoch[3] Time cost=1.678\n",
      "07:38:48 INFO:Epoch[3] Validation-mae=0.093459\n",
      "07:38:48 INFO:Epoch[4] Batch [4]\tSpeed: 312.33 samples/sec\tTrain-mae=0.089450\n",
      "07:38:49 INFO:Epoch[4] Batch [8]\tSpeed: 227.27 samples/sec\tTrain-mae=0.081018\n",
      "07:38:50 INFO:Epoch[4] Batch [12]\tSpeed: 227.45 samples/sec\tTrain-mae=0.066434\n",
      "07:38:50 INFO:Epoch[4] Resetting Data Iterator\n",
      "07:38:50 INFO:Epoch[4] Time cost=1.677\n",
      "07:38:50 INFO:Epoch[4] Validation-mae=0.063293\n",
      "07:38:50 INFO:Epoch[5] Batch [4]\tSpeed: 312.45 samples/sec\tTrain-mae=0.060582\n",
      "07:38:51 INFO:Epoch[5] Batch [8]\tSpeed: 227.73 samples/sec\tTrain-mae=0.089571\n",
      "07:38:52 INFO:Epoch[5] Batch [12]\tSpeed: 227.55 samples/sec\tTrain-mae=0.092012\n",
      "07:38:52 INFO:Epoch[5] Resetting Data Iterator\n",
      "07:38:52 INFO:Epoch[5] Time cost=1.675\n",
      "07:38:52 INFO:Epoch[5] Validation-mae=0.067815\n",
      "07:38:52 INFO:Epoch[6] Batch [4]\tSpeed: 311.81 samples/sec\tTrain-mae=0.083974\n",
      "07:38:53 INFO:Epoch[6] Batch [8]\tSpeed: 227.68 samples/sec\tTrain-mae=0.070774\n",
      "07:38:54 INFO:Epoch[6] Batch [12]\tSpeed: 227.50 samples/sec\tTrain-mae=0.078484\n",
      "07:38:54 INFO:Epoch[6] Resetting Data Iterator\n",
      "07:38:54 INFO:Epoch[6] Time cost=1.676\n",
      "07:38:54 INFO:Epoch[6] Validation-mae=0.088068\n",
      "07:38:54 INFO:Epoch[7] Batch [4]\tSpeed: 305.26 samples/sec\tTrain-mae=0.070631\n",
      "07:38:55 INFO:Epoch[7] Batch [8]\tSpeed: 223.78 samples/sec\tTrain-mae=0.066796\n",
      "07:38:56 INFO:Epoch[7] Batch [12]\tSpeed: 227.37 samples/sec\tTrain-mae=0.059128\n",
      "07:38:56 INFO:Epoch[7] Resetting Data Iterator\n",
      "07:38:56 INFO:Epoch[7] Time cost=1.696\n",
      "07:38:56 INFO:Epoch[7] Validation-mae=0.047446\n",
      "07:38:56 INFO:Epoch[8] Batch [4]\tSpeed: 311.97 samples/sec\tTrain-mae=0.050957\n",
      "07:38:57 INFO:Epoch[8] Batch [8]\tSpeed: 220.01 samples/sec\tTrain-mae=0.062260\n",
      "07:38:58 INFO:Epoch[8] Batch [12]\tSpeed: 224.15 samples/sec\tTrain-mae=0.062833\n",
      "07:38:58 INFO:Epoch[8] Resetting Data Iterator\n",
      "07:38:58 INFO:Epoch[8] Time cost=1.704\n",
      "07:38:58 INFO:Epoch[8] Validation-mae=0.055439\n",
      "07:38:58 INFO:Epoch[9] Batch [4]\tSpeed: 312.22 samples/sec\tTrain-mae=0.059507\n",
      "07:38:59 INFO:Epoch[9] Batch [8]\tSpeed: 227.18 samples/sec\tTrain-mae=0.049409\n",
      "07:39:00 INFO:Epoch[9] Batch [12]\tSpeed: 227.50 samples/sec\tTrain-mae=0.040717\n",
      "07:39:00 INFO:Epoch[9] Resetting Data Iterator\n",
      "07:39:00 INFO:Epoch[9] Time cost=1.677\n",
      "07:39:00 INFO:Epoch[9] Validation-mae=0.049018\n",
      "07:39:00 INFO:Epoch[10] Batch [4]\tSpeed: 311.87 samples/sec\tTrain-mae=0.044022\n",
      "07:39:01 INFO:Epoch[10] Batch [8]\tSpeed: 227.80 samples/sec\tTrain-mae=0.048017\n",
      "07:39:02 INFO:Epoch[10] Batch [12]\tSpeed: 227.60 samples/sec\tTrain-mae=0.042853\n",
      "07:39:02 INFO:Epoch[10] Resetting Data Iterator\n",
      "07:39:02 INFO:Epoch[10] Time cost=1.676\n",
      "07:39:02 INFO:Epoch[10] Validation-mae=0.033564\n",
      "07:39:02 INFO:Epoch[11] Batch [4]\tSpeed: 312.54 samples/sec\tTrain-mae=0.035405\n",
      "07:39:03 INFO:Epoch[11] Batch [8]\tSpeed: 227.38 samples/sec\tTrain-mae=0.047061\n",
      "07:39:04 INFO:Epoch[11] Batch [12]\tSpeed: 227.57 samples/sec\tTrain-mae=0.047004\n",
      "07:39:04 INFO:Epoch[11] Resetting Data Iterator\n",
      "07:39:04 INFO:Epoch[11] Time cost=1.675\n",
      "07:39:04 INFO:Epoch[11] Validation-mae=0.049875\n",
      "07:39:04 INFO:Epoch[12] Batch [4]\tSpeed: 312.14 samples/sec\tTrain-mae=0.044337\n",
      "07:39:05 INFO:Epoch[12] Batch [8]\tSpeed: 227.78 samples/sec\tTrain-mae=0.039647\n",
      "07:39:06 INFO:Epoch[12] Batch [12]\tSpeed: 227.75 samples/sec\tTrain-mae=0.047691\n",
      "07:39:06 INFO:Epoch[12] Resetting Data Iterator\n",
      "07:39:06 INFO:Epoch[12] Time cost=1.675\n",
      "07:39:06 INFO:Epoch[12] Validation-mae=0.039970\n",
      "07:39:06 INFO:Epoch[13] Batch [4]\tSpeed: 311.85 samples/sec\tTrain-mae=0.047484\n",
      "07:39:07 INFO:Epoch[13] Batch [8]\tSpeed: 227.39 samples/sec\tTrain-mae=0.035928\n",
      "07:39:08 INFO:Epoch[13] Batch [12]\tSpeed: 226.31 samples/sec\tTrain-mae=0.042236\n",
      "07:39:08 INFO:Epoch[13] Resetting Data Iterator\n",
      "07:39:08 INFO:Epoch[13] Time cost=1.681\n",
      "07:39:08 INFO:Epoch[13] Validation-mae=0.044584\n",
      "07:39:08 INFO:Epoch[14] Batch [4]\tSpeed: 312.27 samples/sec\tTrain-mae=0.043376\n",
      "07:39:09 INFO:Epoch[14] Batch [8]\tSpeed: 227.34 samples/sec\tTrain-mae=0.037666\n",
      "07:39:10 INFO:Epoch[14] Batch [12]\tSpeed: 227.72 samples/sec\tTrain-mae=0.040791\n",
      "07:39:10 INFO:Epoch[14] Resetting Data Iterator\n",
      "07:39:10 INFO:Epoch[14] Time cost=1.676\n",
      "07:39:10 INFO:Epoch[14] Validation-mae=0.043885\n",
      "07:39:10 INFO:Epoch[15] Batch [4]\tSpeed: 312.50 samples/sec\tTrain-mae=0.038419\n",
      "07:39:11 INFO:Epoch[15] Batch [8]\tSpeed: 227.84 samples/sec\tTrain-mae=0.033062\n",
      "07:39:12 INFO:Epoch[15] Batch [12]\tSpeed: 226.74 samples/sec\tTrain-mae=0.041341\n",
      "07:39:12 INFO:Epoch[15] Resetting Data Iterator\n",
      "07:39:12 INFO:Epoch[15] Time cost=1.677\n",
      "07:39:12 INFO:Epoch[15] Validation-mae=0.035170\n",
      "07:39:12 INFO:Epoch[16] Batch [4]\tSpeed: 310.39 samples/sec\tTrain-mae=0.043612\n",
      "07:39:13 INFO:Epoch[16] Batch [8]\tSpeed: 227.61 samples/sec\tTrain-mae=0.035059\n",
      "07:39:14 INFO:Epoch[16] Batch [12]\tSpeed: 227.83 samples/sec\tTrain-mae=0.037910\n",
      "07:39:14 INFO:Epoch[16] Resetting Data Iterator\n",
      "07:39:14 INFO:Epoch[16] Time cost=1.678\n",
      "07:39:14 INFO:Epoch[16] Validation-mae=0.033439\n",
      "07:39:14 INFO:Epoch[17] Batch [4]\tSpeed: 312.21 samples/sec\tTrain-mae=0.035455\n",
      "07:39:15 INFO:Epoch[17] Batch [8]\tSpeed: 227.09 samples/sec\tTrain-mae=0.034250\n",
      "07:39:16 INFO:Epoch[17] Batch [12]\tSpeed: 223.15 samples/sec\tTrain-mae=0.040372\n",
      "07:39:16 INFO:Epoch[17] Resetting Data Iterator\n",
      "07:39:16 INFO:Epoch[17] Time cost=1.688\n",
      "07:39:16 INFO:Epoch[17] Validation-mae=0.041532\n",
      "07:39:16 INFO:Epoch[18] Batch [4]\tSpeed: 312.47 samples/sec\tTrain-mae=0.038741\n",
      "07:39:17 INFO:Epoch[18] Batch [8]\tSpeed: 227.66 samples/sec\tTrain-mae=0.033486\n",
      "07:39:18 INFO:Epoch[18] Batch [12]\tSpeed: 227.61 samples/sec\tTrain-mae=0.031978\n",
      "07:39:18 INFO:Epoch[18] Resetting Data Iterator\n",
      "07:39:18 INFO:Epoch[18] Time cost=1.675\n",
      "07:39:18 INFO:Epoch[18] Validation-mae=0.034039\n",
      "07:39:18 INFO:Epoch[19] Batch [4]\tSpeed: 312.39 samples/sec\tTrain-mae=0.035515\n",
      "07:39:19 INFO:Epoch[19] Batch [8]\tSpeed: 227.85 samples/sec\tTrain-mae=0.026013\n",
      "07:39:20 INFO:Epoch[19] Batch [12]\tSpeed: 227.79 samples/sec\tTrain-mae=0.032890\n",
      "07:39:20 INFO:Epoch[19] Resetting Data Iterator\n",
      "07:39:20 INFO:Epoch[19] Time cost=1.674\n",
      "07:39:20 INFO:Epoch[19] Validation-mae=0.034166\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Result 0: Validation Accuracy: ('mae', 0.034165979479439557), Params: {'squeeze_factor': 1.0, 'final_dropout': 0.1, 'intermediate_dropout': 0.0, 'conv_constant': 8, 'squeeze_constant': 8, 'mult_factor': 2, 'final_num_features': 160, 'conv_factor': 16, 'dilate_layers': 1, 'weight_decay': 0.0} \""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[(FeedForward(allow_extra_params=False,\n",
       "        arg_params={'squeeze_final_bias': <mxnet.ndarray.NDArray object at 0x2b5dbdef0ad0>, 'decoder_weight': <mxnet.ndarray.NDArray object at 0x2b5dbdef0b10>, 'decoder_bias': <mxnet.ndarray.NDArray object at 0x2b5dbdef0a10>, 'squeeze_post_1_bias': <mxnet.ndarray.NDArray object at 0x2b5dbdef0f10>, 'leakyrel...bject at 0x2b5dbdef0190>, 'squeeze_post_1_weight': <mxnet.ndarray.NDArray object at 0x2b5dbdef0690>},\n",
       "        aux_params={}, begin_epoch=0, ctx=[gpu(0)], epoch_size=None,\n",
       "        initializer=<mxnet.initializer.Uniform object at 0x2b5dbdc31dd0>,\n",
       "        num_epoch=20, numpy_batch_size=128,\n",
       "        optimizer=<myopt.MyAdaGrad object at 0x2b5dc4998410>,\n",
       "        symbol=<mxnet.symbol.Symbol object at 0x2b5dc4998110>),\n",
       "  {'conv_constant': 8,\n",
       "   'conv_factor': 16,\n",
       "   'dilate_layers': 1,\n",
       "   'final_dropout': 0.1,\n",
       "   'final_num_features': 160,\n",
       "   'intermediate_dropout': 0.0,\n",
       "   'mult_factor': 2,\n",
       "   'squeeze_constant': 8,\n",
       "   'squeeze_factor': 0.5,\n",
       "   'weight_decay': 0.0},\n",
       "  ('mae', 0.045969190075993538)),\n",
       " (FeedForward(allow_extra_params=False,\n",
       "        arg_params={'squeeze_final_bias': <mxnet.ndarray.NDArray object at 0x2b5dc495f450>, 'decoder_weight': <mxnet.ndarray.NDArray object at 0x2b5dc495f490>, 'decoder_bias': <mxnet.ndarray.NDArray object at 0x2b5dbdf48e50>, 'squeeze_post_1_bias': <mxnet.ndarray.NDArray object at 0x2b5dc495f9d0>, 'squeeze_...bject at 0x2b5dc495f350>, 'squeeze_post_1_weight': <mxnet.ndarray.NDArray object at 0x2b5dc7fcdfd0>},\n",
       "        aux_params={}, begin_epoch=0, ctx=[gpu(0)], epoch_size=None,\n",
       "        initializer=<mxnet.initializer.Uniform object at 0x2b5dbdc31dd0>,\n",
       "        num_epoch=20, numpy_batch_size=128,\n",
       "        optimizer=<myopt.MyAdaGrad object at 0x2b5dc4998490>,\n",
       "        symbol=<mxnet.symbol.Symbol object at 0x2b5dbdef0750>),\n",
       "  {'conv_constant': 8,\n",
       "   'conv_factor': 16,\n",
       "   'dilate_layers': 1,\n",
       "   'final_dropout': 0.1,\n",
       "   'final_num_features': 160,\n",
       "   'intermediate_dropout': 0.0,\n",
       "   'mult_factor': 2,\n",
       "   'squeeze_constant': 8,\n",
       "   'squeeze_factor': 1.0,\n",
       "   'weight_decay': 0.0},\n",
       "  ('mae', 0.029254060937091708)),\n",
       " (FeedForward(allow_extra_params=False,\n",
       "        arg_params={'squeeze_final_bias': <mxnet.ndarray.NDArray object at 0x2b5dbdf488d0>, 'squeeze_post_1_weight': <mxnet.ndarray.NDArray object at 0x2b5dbdf54710>, 'decoder_bias': <mxnet.ndarray.NDArray object at 0x2b5dbdf48250>, 'squeeze_post_1_bias': <mxnet.ndarray.NDArray object at 0x2b5dbdf54950>, 'l...Array object at 0x2b5dbdf48110>, 'decoder_weight': <mxnet.ndarray.NDArray object at 0x2b5dbdf48610>},\n",
       "        aux_params={}, begin_epoch=0, ctx=[gpu(0)], epoch_size=None,\n",
       "        initializer=<mxnet.initializer.Uniform object at 0x2b5dbdc31dd0>,\n",
       "        num_epoch=20, numpy_batch_size=128,\n",
       "        optimizer=<myopt.MyAdaGrad object at 0x2b5dc8015e90>,\n",
       "        symbol=<mxnet.symbol.Symbol object at 0x2b5dc49a3e10>),\n",
       "  {'conv_constant': 8,\n",
       "   'conv_factor': 16,\n",
       "   'dilate_layers': 1,\n",
       "   'final_dropout': 0.1,\n",
       "   'final_num_features': 160,\n",
       "   'intermediate_dropout': 0.0,\n",
       "   'mult_factor': 2,\n",
       "   'squeeze_constant': 8,\n",
       "   'squeeze_factor': 0.5,\n",
       "   'weight_decay': 0.0},\n",
       "  ('mae', 0.057329071220010519)),\n",
       " (FeedForward(allow_extra_params=False,\n",
       "        arg_params={'squeeze_final_bias': <mxnet.ndarray.NDArray object at 0x2b5dc7b6bd50>, 'squeeze_post_1_weight': <mxnet.ndarray.NDArray object at 0x2b5dc7b6bad0>, 'decoder_bias': <mxnet.ndarray.NDArray object at 0x2b5dc7b6bc50>, 'squeeze_post_1_bias': <mxnet.ndarray.NDArray object at 0x2b5dc7b6b610>, 'squeeze_final_weight': <mxnet.ndarray.NDArray object at 0x2b5dc7b6ba90>, 'decoder_weight': <mxnet.ndarray.NDArray object at 0x2b5dc7b6b650>},\n",
       "        aux_params={}, begin_epoch=0, ctx=[gpu(0)], epoch_size=None,\n",
       "        initializer=<mxnet.initializer.Uniform object at 0x2b5dbdc31dd0>,\n",
       "        num_epoch=20, numpy_batch_size=128,\n",
       "        optimizer=<myopt.MyAdaGrad object at 0x2b5dc7ff7f90>,\n",
       "        symbol=<mxnet.symbol.Symbol object at 0x2b5dbdc3af90>),\n",
       "  {'conv_constant': 8,\n",
       "   'conv_factor': 16,\n",
       "   'dilate_layers': 1,\n",
       "   'final_dropout': 0.1,\n",
       "   'final_num_features': 160,\n",
       "   'intermediate_dropout': 0.0,\n",
       "   'mult_factor': 2,\n",
       "   'squeeze_constant': 8,\n",
       "   'squeeze_factor': 0.5,\n",
       "   'weight_decay': 0.0},\n",
       "  ('mae', 0.070235596038401127)),\n",
       " (None,\n",
       "  {'conv_constant': 8,\n",
       "   'conv_factor': 16,\n",
       "   'dilate_layers': 1,\n",
       "   'final_dropout': 0.1,\n",
       "   'final_num_features': 160,\n",
       "   'intermediate_dropout': 0.0,\n",
       "   'mult_factor': 2,\n",
       "   'squeeze_constant': 8,\n",
       "   'squeeze_factor': 0.5,\n",
       "   'weight_decay': 0.0},\n",
       "  None),\n",
       " (None,\n",
       "  {'conv_constant': 8,\n",
       "   'conv_factor': 16,\n",
       "   'dilate_layers': 1,\n",
       "   'final_dropout': 0.1,\n",
       "   'final_num_features': 160,\n",
       "   'intermediate_dropout': 0.0,\n",
       "   'mult_factor': 2,\n",
       "   'squeeze_constant': 8,\n",
       "   'squeeze_factor': 1.0,\n",
       "   'weight_decay': 0.0},\n",
       "  None),\n",
       " (FeedForward(allow_extra_params=False,\n",
       "        arg_params={'squeeze_final_bias': <mxnet.ndarray.NDArray object at 0x2b5dc7b6b710>, 'squeeze_post_1_weight': <mxnet.ndarray.NDArray object at 0x2b5dc7b6bd10>, 'decoder_bias': <mxnet.ndarray.NDArray object at 0x2b5dc7b6bc90>, 'squeeze_post_1_bias': <mxnet.ndarray.NDArray object at 0x2b5dc7b6bc10>, 'squeeze_final_weight': <mxnet.ndarray.NDArray object at 0x2b5dc7b6bf50>, 'decoder_weight': <mxnet.ndarray.NDArray object at 0x2b5dc7b6b750>},\n",
       "        aux_params={}, begin_epoch=0, ctx=[gpu(0), gpu(1)], epoch_size=None,\n",
       "        initializer=<mxnet.initializer.Uniform object at 0x2b5dbdc31dd0>,\n",
       "        num_epoch=20, numpy_batch_size=128,\n",
       "        optimizer=<myopt.MyAdaGrad object at 0x2b5dbdc0f910>,\n",
       "        symbol=<mxnet.symbol.Symbol object at 0x2b5dbdc0f150>),\n",
       "  {'conv_constant': 8,\n",
       "   'conv_factor': 16,\n",
       "   'dilate_layers': 1,\n",
       "   'final_dropout': 0.1,\n",
       "   'final_num_features': 160,\n",
       "   'intermediate_dropout': 0.0,\n",
       "   'mult_factor': 2,\n",
       "   'squeeze_constant': 8,\n",
       "   'squeeze_factor': 1.0,\n",
       "   'weight_decay': 0.0},\n",
       "  ('mae', 0.063215745845809579)),\n",
       " (FeedForward(allow_extra_params=False,\n",
       "        arg_params={'squeeze_final_bias': <mxnet.ndarray.NDArray object at 0x2b5dc7b814d0>, 'squeeze_post_1_weight': <mxnet.ndarray.NDArray object at 0x2b5dc7b78d90>, 'decoder_bias': <mxnet.ndarray.NDArray object at 0x2b5dc7b81610>, 'squeeze_post_1_bias': <mxnet.ndarray.NDArray object at 0x2b5dc7b78c50>, 'squeeze_final_weight': <mxnet.ndarray.NDArray object at 0x2b5dc7b81690>, 'decoder_weight': <mxnet.ndarray.NDArray object at 0x2b5dc7b81210>},\n",
       "        aux_params={}, begin_epoch=0, ctx=[gpu(0), gpu(1)], epoch_size=None,\n",
       "        initializer=<mxnet.initializer.Uniform object at 0x2b5dbdc31dd0>,\n",
       "        num_epoch=20, numpy_batch_size=128,\n",
       "        optimizer=<myopt.MyAdaGrad object at 0x2b5dc8015fd0>,\n",
       "        symbol=<mxnet.symbol.Symbol object at 0x2b5dbdec9bd0>),\n",
       "  {'conv_constant': 8,\n",
       "   'conv_factor': 16,\n",
       "   'dilate_layers': 1,\n",
       "   'final_dropout': 0.1,\n",
       "   'final_num_features': 160,\n",
       "   'intermediate_dropout': 0.0,\n",
       "   'mult_factor': 2,\n",
       "   'squeeze_constant': 8,\n",
       "   'squeeze_factor': 1.0,\n",
       "   'weight_decay': 0.0},\n",
       "  ('mae', 0.052066597621887922)),\n",
       " (FeedForward(allow_extra_params=False,\n",
       "        arg_params={'squeeze_final_bias': <mxnet.ndarray.NDArray object at 0x2b5dc49ad310>, 'decoder_bias': <mxnet.ndarray.NDArray object at 0x2b5dc49ad910>, 'decoder_weight': <mxnet.ndarray.NDArray object at 0x2b5dc49ada50>, 'squeeze_final_weight': <mxnet.ndarray.NDArray object at 0x2b5dc49ad6d0>, 'squeeze...bject at 0x2b5dc49ade90>, 'squeeze_post_1_weight': <mxnet.ndarray.NDArray object at 0x2b5dc49bd950>},\n",
       "        aux_params={}, begin_epoch=0, ctx=[gpu(0), gpu(1)], epoch_size=None,\n",
       "        initializer=<mxnet.initializer.Uniform object at 0x2b5dbdc31dd0>,\n",
       "        num_epoch=20, numpy_batch_size=128,\n",
       "        optimizer=<myopt.MyAdaGrad object at 0x2b5dbdf48750>,\n",
       "        symbol=<mxnet.symbol.Symbol object at 0x2b5dc7b6b9d0>),\n",
       "  {'conv_constant': 8,\n",
       "   'conv_factor': 16,\n",
       "   'dilate_layers': 1,\n",
       "   'final_dropout': 0.1,\n",
       "   'final_num_features': 160,\n",
       "   'intermediate_dropout': 0.0,\n",
       "   'mult_factor': 2,\n",
       "   'squeeze_constant': 8,\n",
       "   'squeeze_factor': 1.0,\n",
       "   'weight_decay': 0.0},\n",
       "  ('mae', 0.02783476747572422)),\n",
       " (FeedForward(allow_extra_params=False,\n",
       "        arg_params={'squeeze_final_bias': <mxnet.ndarray.NDArray object at 0x2b5dc4a3a710>, 'squeeze_post_1_weight': <mxnet.ndarray.NDArray object at 0x2b5dc4a3a550>, 'decoder_bias': <mxnet.ndarray.NDArray object at 0x2b5dc4a3a5d0>, 'squeeze_post_1_bias': <mxnet.ndarray.NDArray object at 0x2b5dc4a3a650>, 's...Array object at 0x2b5dc4a3a790>, 'decoder_weight': <mxnet.ndarray.NDArray object at 0x2b5dc4a3ab50>},\n",
       "        aux_params={}, begin_epoch=0, ctx=[gpu(0), gpu(1)], epoch_size=None,\n",
       "        initializer=<mxnet.initializer.Uniform object at 0x2b5dbdc31dd0>,\n",
       "        num_epoch=20, numpy_batch_size=128,\n",
       "        optimizer=<myopt.MyAdaGrad object at 0x2b5dc49a37d0>,\n",
       "        symbol=<mxnet.symbol.Symbol object at 0x2b5dbdc3afd0>),\n",
       "  {'conv_constant': 8,\n",
       "   'conv_factor': 16,\n",
       "   'dilate_layers': 1,\n",
       "   'final_dropout': 0.1,\n",
       "   'final_num_features': 160,\n",
       "   'intermediate_dropout': 0.0,\n",
       "   'mult_factor': 2,\n",
       "   'squeeze_constant': 8,\n",
       "   'squeeze_factor': 1.0,\n",
       "   'weight_decay': 0.0},\n",
       "  ('mae', 0.034165979479439557))]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:39:20 INFO:Auto-select kvstore type = local_update_cpu\n",
      "07:39:20 INFO:Start training with [gpu(0), gpu(1)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with {'squeeze_factor': 0.5, 'final_dropout': 0.1, 'intermediate_dropout': 0.0, 'conv_constant': 8, 'squeeze_constant': 8, 'mult_factor': 2, 'final_num_features': 160, 'conv_factor': 16, 'dilate_layers': 1, 'weight_decay': 0.0}\n",
      "Creating Model with params {'squeeze_factor': 0.5, 'final_dropout': 0.1, 'intermediate_dropout': 0.0, 'conv_constant': 8, 'squeeze_constant': 8, 'mult_factor': 2, 'final_num_features': 160, 'conv_factor': 16, 'dilate_layers': 1, 'weight_decay': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:39:20 INFO:Epoch[0] Batch [4]\tSpeed: 312.39 samples/sec\tTrain-mae=0.681333\n",
      "07:39:21 INFO:Epoch[0] Batch [8]\tSpeed: 226.14 samples/sec\tTrain-mae=0.121450\n",
      "07:39:22 INFO:Epoch[0] Batch [12]\tSpeed: 227.83 samples/sec\tTrain-mae=0.125042\n",
      "07:39:22 INFO:Epoch[0] Resetting Data Iterator\n",
      "07:39:22 INFO:Epoch[0] Time cost=1.680\n",
      "07:39:22 INFO:Epoch[0] Validation-mae=0.135010\n",
      "07:39:22 INFO:Epoch[1] Batch [4]\tSpeed: 312.46 samples/sec\tTrain-mae=0.123985\n",
      "07:39:23 INFO:Epoch[1] Batch [8]\tSpeed: 227.75 samples/sec\tTrain-mae=0.096450\n",
      "07:39:24 INFO:Epoch[1] Batch [12]\tSpeed: 227.81 samples/sec\tTrain-mae=0.110471\n",
      "07:39:24 INFO:Epoch[1] Resetting Data Iterator\n",
      "07:39:24 INFO:Epoch[1] Time cost=1.675\n",
      "07:39:24 INFO:Epoch[1] Validation-mae=0.135333\n",
      "07:39:24 INFO:Epoch[2] Batch [4]\tSpeed: 312.27 samples/sec\tTrain-mae=0.115633\n",
      "07:39:25 INFO:Epoch[2] Batch [8]\tSpeed: 227.90 samples/sec\tTrain-mae=0.124831\n",
      "07:39:26 INFO:Epoch[2] Batch [12]\tSpeed: 209.24 samples/sec\tTrain-mae=0.101182\n",
      "07:39:26 INFO:Epoch[2] Resetting Data Iterator\n",
      "07:39:26 INFO:Epoch[2] Time cost=1.724\n",
      "07:39:26 INFO:Epoch[2] Validation-mae=0.133516\n",
      "07:39:27 INFO:Epoch[3] Batch [4]\tSpeed: 300.38 samples/sec\tTrain-mae=0.122679\n",
      "07:39:27 INFO:Epoch[3] Batch [8]\tSpeed: 223.20 samples/sec\tTrain-mae=0.116746\n",
      "07:39:28 INFO:Epoch[3] Batch [12]\tSpeed: 224.04 samples/sec\tTrain-mae=0.110653\n",
      "07:39:28 INFO:Epoch[3] Resetting Data Iterator\n",
      "07:39:28 INFO:Epoch[3] Time cost=1.764\n",
      "07:39:28 INFO:Epoch[3] Validation-mae=0.092273\n",
      "07:39:29 INFO:Epoch[4] Batch [4]\tSpeed: 311.22 samples/sec\tTrain-mae=0.092441\n",
      "07:39:29 INFO:Epoch[4] Batch [8]\tSpeed: 219.71 samples/sec\tTrain-mae=0.095130\n",
      "07:39:30 INFO:Epoch[4] Batch [12]\tSpeed: 225.16 samples/sec\tTrain-mae=0.082032\n",
      "07:39:30 INFO:Epoch[4] Resetting Data Iterator\n",
      "07:39:30 INFO:Epoch[4] Time cost=1.704\n",
      "07:39:30 INFO:Epoch[4] Validation-mae=0.126898\n",
      "07:39:31 INFO:Epoch[5] Batch [4]\tSpeed: 312.41 samples/sec\tTrain-mae=0.097395\n",
      "07:39:31 INFO:Epoch[5] Batch [8]\tSpeed: 225.33 samples/sec\tTrain-mae=0.097776\n",
      "07:39:32 INFO:Epoch[5] Batch [12]\tSpeed: 227.74 samples/sec\tTrain-mae=0.076674\n",
      "07:39:32 INFO:Epoch[5] Resetting Data Iterator\n",
      "07:39:32 INFO:Epoch[5] Time cost=1.681\n",
      "07:39:32 INFO:Epoch[5] Validation-mae=0.079220\n",
      "07:39:33 INFO:Epoch[6] Batch [4]\tSpeed: 312.78 samples/sec\tTrain-mae=0.076300\n",
      "07:39:33 INFO:Epoch[6] Batch [8]\tSpeed: 227.57 samples/sec\tTrain-mae=0.083676\n",
      "07:39:34 INFO:Epoch[6] Batch [12]\tSpeed: 226.98 samples/sec\tTrain-mae=0.070846\n",
      "07:39:34 INFO:Epoch[6] Resetting Data Iterator\n",
      "07:39:34 INFO:Epoch[6] Time cost=1.677\n",
      "07:39:34 INFO:Epoch[6] Validation-mae=0.070508\n",
      "07:39:35 INFO:Epoch[7] Batch [4]\tSpeed: 310.73 samples/sec\tTrain-mae=0.066849\n",
      "07:39:35 INFO:Epoch[7] Batch [8]\tSpeed: 227.31 samples/sec\tTrain-mae=0.063743\n",
      "07:39:36 INFO:Epoch[7] Batch [12]\tSpeed: 227.76 samples/sec\tTrain-mae=0.051225\n",
      "07:39:36 INFO:Epoch[7] Resetting Data Iterator\n",
      "07:39:36 INFO:Epoch[7] Time cost=1.679\n",
      "07:39:36 INFO:Epoch[7] Validation-mae=0.060871\n",
      "07:39:37 INFO:Epoch[8] Batch [4]\tSpeed: 312.35 samples/sec\tTrain-mae=0.057748\n",
      "07:39:37 INFO:Epoch[8] Batch [8]\tSpeed: 227.70 samples/sec\tTrain-mae=0.055598\n",
      "07:39:38 INFO:Epoch[8] Batch [12]\tSpeed: 227.64 samples/sec\tTrain-mae=0.048510\n",
      "07:39:38 INFO:Epoch[8] Resetting Data Iterator\n",
      "07:39:38 INFO:Epoch[8] Time cost=1.675\n",
      "07:39:38 INFO:Epoch[8] Validation-mae=0.072761\n",
      "07:39:39 INFO:Epoch[9] Batch [4]\tSpeed: 311.39 samples/sec\tTrain-mae=0.050487\n",
      "07:39:39 INFO:Epoch[9] Batch [8]\tSpeed: 227.49 samples/sec\tTrain-mae=0.051274\n",
      "07:39:40 INFO:Epoch[9] Batch [12]\tSpeed: 227.54 samples/sec\tTrain-mae=0.051862\n",
      "07:39:40 INFO:Epoch[9] Resetting Data Iterator\n",
      "07:39:40 INFO:Epoch[9] Time cost=1.679\n",
      "07:39:40 INFO:Epoch[9] Validation-mae=0.053323\n",
      "07:39:41 INFO:Epoch[10] Batch [4]\tSpeed: 302.75 samples/sec\tTrain-mae=0.050957\n",
      "07:39:41 INFO:Epoch[10] Batch [8]\tSpeed: 225.82 samples/sec\tTrain-mae=0.057652\n",
      "07:39:42 INFO:Epoch[10] Batch [12]\tSpeed: 196.36 samples/sec\tTrain-mae=0.047377\n",
      "07:39:42 INFO:Epoch[10] Resetting Data Iterator\n",
      "07:39:42 INFO:Epoch[10] Time cost=1.943\n",
      "07:39:42 INFO:Epoch[10] Validation-mae=0.035848\n",
      "07:39:43 INFO:Epoch[11] Batch [4]\tSpeed: 309.07 samples/sec\tTrain-mae=0.046940\n",
      "07:39:43 INFO:Epoch[11] Batch [8]\tSpeed: 227.07 samples/sec\tTrain-mae=0.036183\n",
      "07:39:44 INFO:Epoch[11] Batch [12]\tSpeed: 212.82 samples/sec\tTrain-mae=0.038959\n",
      "07:39:44 INFO:Epoch[11] Resetting Data Iterator\n",
      "07:39:44 INFO:Epoch[11] Time cost=1.723\n",
      "07:39:44 INFO:Epoch[11] Validation-mae=0.039135\n",
      "07:39:45 INFO:Epoch[12] Batch [4]\tSpeed: 311.64 samples/sec\tTrain-mae=0.042654\n",
      "07:39:45 INFO:Epoch[12] Batch [8]\tSpeed: 227.35 samples/sec\tTrain-mae=0.037744\n",
      "07:39:46 INFO:Epoch[12] Batch [12]\tSpeed: 224.26 samples/sec\tTrain-mae=0.045340\n",
      "07:39:46 INFO:Epoch[12] Resetting Data Iterator\n",
      "07:39:46 INFO:Epoch[12] Time cost=1.687\n",
      "07:39:46 INFO:Epoch[12] Validation-mae=0.042663\n",
      "07:39:47 INFO:Epoch[13] Batch [4]\tSpeed: 311.87 samples/sec\tTrain-mae=0.053660\n",
      "07:39:47 INFO:Epoch[13] Batch [8]\tSpeed: 227.11 samples/sec\tTrain-mae=0.048438\n",
      "07:39:48 INFO:Epoch[13] Batch [12]\tSpeed: 224.39 samples/sec\tTrain-mae=0.044980\n",
      "07:39:48 INFO:Epoch[13] Resetting Data Iterator\n",
      "07:39:48 INFO:Epoch[13] Time cost=1.686\n",
      "07:39:48 INFO:Epoch[13] Validation-mae=0.041684\n",
      "07:39:49 INFO:Epoch[14] Batch [4]\tSpeed: 308.78 samples/sec\tTrain-mae=0.043323\n",
      "07:39:50 INFO:Epoch[14] Batch [8]\tSpeed: 223.81 samples/sec\tTrain-mae=0.044511\n",
      "07:39:50 INFO:Epoch[14] Batch [12]\tSpeed: 226.28 samples/sec\tTrain-mae=0.054762\n",
      "07:39:50 INFO:Epoch[14] Resetting Data Iterator\n",
      "07:39:50 INFO:Epoch[14] Time cost=1.845\n",
      "07:39:50 INFO:Epoch[14] Validation-mae=0.053118\n",
      "07:39:51 INFO:Epoch[15] Batch [4]\tSpeed: 311.20 samples/sec\tTrain-mae=0.052547\n",
      "07:39:52 INFO:Epoch[15] Batch [8]\tSpeed: 219.80 samples/sec\tTrain-mae=0.050168\n",
      "07:39:52 INFO:Epoch[15] Batch [12]\tSpeed: 224.53 samples/sec\tTrain-mae=0.036107\n",
      "07:39:52 INFO:Epoch[15] Resetting Data Iterator\n",
      "07:39:52 INFO:Epoch[15] Time cost=1.705\n",
      "07:39:52 INFO:Epoch[15] Validation-mae=0.034172\n",
      "07:39:53 INFO:Epoch[16] Batch [4]\tSpeed: 311.56 samples/sec\tTrain-mae=0.035485\n",
      "07:39:54 INFO:Epoch[16] Batch [8]\tSpeed: 227.40 samples/sec\tTrain-mae=0.038355\n",
      "07:39:54 INFO:Epoch[16] Batch [12]\tSpeed: 227.49 samples/sec\tTrain-mae=0.048937\n",
      "07:39:54 INFO:Epoch[16] Resetting Data Iterator\n",
      "07:39:54 INFO:Epoch[16] Time cost=1.678\n",
      "07:39:54 INFO:Epoch[16] Validation-mae=0.051625\n",
      "07:39:55 INFO:Epoch[17] Batch [4]\tSpeed: 312.04 samples/sec\tTrain-mae=0.046096\n",
      "07:39:56 INFO:Epoch[17] Batch [8]\tSpeed: 227.21 samples/sec\tTrain-mae=0.044024\n",
      "07:39:56 INFO:Epoch[17] Batch [12]\tSpeed: 227.43 samples/sec\tTrain-mae=0.044608\n",
      "07:39:56 INFO:Epoch[17] Resetting Data Iterator\n",
      "07:39:56 INFO:Epoch[17] Time cost=1.678\n",
      "07:39:56 INFO:Epoch[17] Validation-mae=0.041344\n",
      "07:39:57 INFO:Epoch[18] Batch [4]\tSpeed: 309.06 samples/sec\tTrain-mae=0.041922\n",
      "07:39:58 INFO:Epoch[18] Batch [8]\tSpeed: 224.48 samples/sec\tTrain-mae=0.046417\n",
      "07:39:58 INFO:Epoch[18] Batch [12]\tSpeed: 227.35 samples/sec\tTrain-mae=0.035088\n",
      "07:39:58 INFO:Epoch[18] Resetting Data Iterator\n",
      "07:39:58 INFO:Epoch[18] Time cost=1.841\n",
      "07:39:59 INFO:Epoch[18] Validation-mae=0.034796\n",
      "07:39:59 INFO:Epoch[19] Batch [4]\tSpeed: 312.30 samples/sec\tTrain-mae=0.032938\n",
      "07:40:00 INFO:Epoch[19] Batch [8]\tSpeed: 227.08 samples/sec\tTrain-mae=0.038163\n",
      "07:40:00 INFO:Epoch[19] Batch [12]\tSpeed: 221.71 samples/sec\tTrain-mae=0.035047\n",
      "07:40:00 INFO:Epoch[19] Resetting Data Iterator\n",
      "07:40:00 INFO:Epoch[19] Time cost=1.692\n",
      "07:40:01 INFO:Epoch[19] Validation-mae=0.038255\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Result 1: Validation Accuracy: ('mae', 0.038254949264228344), Params: {'squeeze_factor': 0.5, 'final_dropout': 0.1, 'intermediate_dropout': 0.0, 'conv_constant': 8, 'squeeze_constant': 8, 'mult_factor': 2, 'final_num_features': 160, 'conv_factor': 16, 'dilate_layers': 1, 'weight_decay': 0.0} \""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[(FeedForward(allow_extra_params=False,\n",
       "        arg_params={'squeeze_final_bias': <mxnet.ndarray.NDArray object at 0x2b5dbdef0ad0>, 'decoder_weight': <mxnet.ndarray.NDArray object at 0x2b5dbdef0b10>, 'decoder_bias': <mxnet.ndarray.NDArray object at 0x2b5dbdef0a10>, 'squeeze_post_1_bias': <mxnet.ndarray.NDArray object at 0x2b5dbdef0f10>, 'leakyrel...bject at 0x2b5dbdef0190>, 'squeeze_post_1_weight': <mxnet.ndarray.NDArray object at 0x2b5dbdef0690>},\n",
       "        aux_params={}, begin_epoch=0, ctx=[gpu(0)], epoch_size=None,\n",
       "        initializer=<mxnet.initializer.Uniform object at 0x2b5dbdc31dd0>,\n",
       "        num_epoch=20, numpy_batch_size=128,\n",
       "        optimizer=<myopt.MyAdaGrad object at 0x2b5dc4998410>,\n",
       "        symbol=<mxnet.symbol.Symbol object at 0x2b5dc4998110>),\n",
       "  {'conv_constant': 8,\n",
       "   'conv_factor': 16,\n",
       "   'dilate_layers': 1,\n",
       "   'final_dropout': 0.1,\n",
       "   'final_num_features': 160,\n",
       "   'intermediate_dropout': 0.0,\n",
       "   'mult_factor': 2,\n",
       "   'squeeze_constant': 8,\n",
       "   'squeeze_factor': 0.5,\n",
       "   'weight_decay': 0.0},\n",
       "  ('mae', 0.045969190075993538)),\n",
       " (FeedForward(allow_extra_params=False,\n",
       "        arg_params={'squeeze_final_bias': <mxnet.ndarray.NDArray object at 0x2b5dc495f450>, 'decoder_weight': <mxnet.ndarray.NDArray object at 0x2b5dc495f490>, 'decoder_bias': <mxnet.ndarray.NDArray object at 0x2b5dbdf48e50>, 'squeeze_post_1_bias': <mxnet.ndarray.NDArray object at 0x2b5dc495f9d0>, 'squeeze_...bject at 0x2b5dc495f350>, 'squeeze_post_1_weight': <mxnet.ndarray.NDArray object at 0x2b5dc7fcdfd0>},\n",
       "        aux_params={}, begin_epoch=0, ctx=[gpu(0)], epoch_size=None,\n",
       "        initializer=<mxnet.initializer.Uniform object at 0x2b5dbdc31dd0>,\n",
       "        num_epoch=20, numpy_batch_size=128,\n",
       "        optimizer=<myopt.MyAdaGrad object at 0x2b5dc4998490>,\n",
       "        symbol=<mxnet.symbol.Symbol object at 0x2b5dbdef0750>),\n",
       "  {'conv_constant': 8,\n",
       "   'conv_factor': 16,\n",
       "   'dilate_layers': 1,\n",
       "   'final_dropout': 0.1,\n",
       "   'final_num_features': 160,\n",
       "   'intermediate_dropout': 0.0,\n",
       "   'mult_factor': 2,\n",
       "   'squeeze_constant': 8,\n",
       "   'squeeze_factor': 1.0,\n",
       "   'weight_decay': 0.0},\n",
       "  ('mae', 0.029254060937091708)),\n",
       " (FeedForward(allow_extra_params=False,\n",
       "        arg_params={'squeeze_final_bias': <mxnet.ndarray.NDArray object at 0x2b5dbdf488d0>, 'squeeze_post_1_weight': <mxnet.ndarray.NDArray object at 0x2b5dbdf54710>, 'decoder_bias': <mxnet.ndarray.NDArray object at 0x2b5dbdf48250>, 'squeeze_post_1_bias': <mxnet.ndarray.NDArray object at 0x2b5dbdf54950>, 'l...Array object at 0x2b5dbdf48110>, 'decoder_weight': <mxnet.ndarray.NDArray object at 0x2b5dbdf48610>},\n",
       "        aux_params={}, begin_epoch=0, ctx=[gpu(0)], epoch_size=None,\n",
       "        initializer=<mxnet.initializer.Uniform object at 0x2b5dbdc31dd0>,\n",
       "        num_epoch=20, numpy_batch_size=128,\n",
       "        optimizer=<myopt.MyAdaGrad object at 0x2b5dc8015e90>,\n",
       "        symbol=<mxnet.symbol.Symbol object at 0x2b5dc49a3e10>),\n",
       "  {'conv_constant': 8,\n",
       "   'conv_factor': 16,\n",
       "   'dilate_layers': 1,\n",
       "   'final_dropout': 0.1,\n",
       "   'final_num_features': 160,\n",
       "   'intermediate_dropout': 0.0,\n",
       "   'mult_factor': 2,\n",
       "   'squeeze_constant': 8,\n",
       "   'squeeze_factor': 0.5,\n",
       "   'weight_decay': 0.0},\n",
       "  ('mae', 0.057329071220010519)),\n",
       " (FeedForward(allow_extra_params=False,\n",
       "        arg_params={'squeeze_final_bias': <mxnet.ndarray.NDArray object at 0x2b5dc7b6bd50>, 'squeeze_post_1_weight': <mxnet.ndarray.NDArray object at 0x2b5dc7b6bad0>, 'decoder_bias': <mxnet.ndarray.NDArray object at 0x2b5dc7b6bc50>, 'squeeze_post_1_bias': <mxnet.ndarray.NDArray object at 0x2b5dc7b6b610>, 'squeeze_final_weight': <mxnet.ndarray.NDArray object at 0x2b5dc7b6ba90>, 'decoder_weight': <mxnet.ndarray.NDArray object at 0x2b5dc7b6b650>},\n",
       "        aux_params={}, begin_epoch=0, ctx=[gpu(0)], epoch_size=None,\n",
       "        initializer=<mxnet.initializer.Uniform object at 0x2b5dbdc31dd0>,\n",
       "        num_epoch=20, numpy_batch_size=128,\n",
       "        optimizer=<myopt.MyAdaGrad object at 0x2b5dc7ff7f90>,\n",
       "        symbol=<mxnet.symbol.Symbol object at 0x2b5dbdc3af90>),\n",
       "  {'conv_constant': 8,\n",
       "   'conv_factor': 16,\n",
       "   'dilate_layers': 1,\n",
       "   'final_dropout': 0.1,\n",
       "   'final_num_features': 160,\n",
       "   'intermediate_dropout': 0.0,\n",
       "   'mult_factor': 2,\n",
       "   'squeeze_constant': 8,\n",
       "   'squeeze_factor': 0.5,\n",
       "   'weight_decay': 0.0},\n",
       "  ('mae', 0.070235596038401127)),\n",
       " (None,\n",
       "  {'conv_constant': 8,\n",
       "   'conv_factor': 16,\n",
       "   'dilate_layers': 1,\n",
       "   'final_dropout': 0.1,\n",
       "   'final_num_features': 160,\n",
       "   'intermediate_dropout': 0.0,\n",
       "   'mult_factor': 2,\n",
       "   'squeeze_constant': 8,\n",
       "   'squeeze_factor': 0.5,\n",
       "   'weight_decay': 0.0},\n",
       "  None),\n",
       " (None,\n",
       "  {'conv_constant': 8,\n",
       "   'conv_factor': 16,\n",
       "   'dilate_layers': 1,\n",
       "   'final_dropout': 0.1,\n",
       "   'final_num_features': 160,\n",
       "   'intermediate_dropout': 0.0,\n",
       "   'mult_factor': 2,\n",
       "   'squeeze_constant': 8,\n",
       "   'squeeze_factor': 1.0,\n",
       "   'weight_decay': 0.0},\n",
       "  None),\n",
       " (FeedForward(allow_extra_params=False,\n",
       "        arg_params={'squeeze_final_bias': <mxnet.ndarray.NDArray object at 0x2b5dc7b6b710>, 'squeeze_post_1_weight': <mxnet.ndarray.NDArray object at 0x2b5dc7b6bd10>, 'decoder_bias': <mxnet.ndarray.NDArray object at 0x2b5dc7b6bc90>, 'squeeze_post_1_bias': <mxnet.ndarray.NDArray object at 0x2b5dc7b6bc10>, 'squeeze_final_weight': <mxnet.ndarray.NDArray object at 0x2b5dc7b6bf50>, 'decoder_weight': <mxnet.ndarray.NDArray object at 0x2b5dc7b6b750>},\n",
       "        aux_params={}, begin_epoch=0, ctx=[gpu(0), gpu(1)], epoch_size=None,\n",
       "        initializer=<mxnet.initializer.Uniform object at 0x2b5dbdc31dd0>,\n",
       "        num_epoch=20, numpy_batch_size=128,\n",
       "        optimizer=<myopt.MyAdaGrad object at 0x2b5dbdc0f910>,\n",
       "        symbol=<mxnet.symbol.Symbol object at 0x2b5dbdc0f150>),\n",
       "  {'conv_constant': 8,\n",
       "   'conv_factor': 16,\n",
       "   'dilate_layers': 1,\n",
       "   'final_dropout': 0.1,\n",
       "   'final_num_features': 160,\n",
       "   'intermediate_dropout': 0.0,\n",
       "   'mult_factor': 2,\n",
       "   'squeeze_constant': 8,\n",
       "   'squeeze_factor': 1.0,\n",
       "   'weight_decay': 0.0},\n",
       "  ('mae', 0.063215745845809579)),\n",
       " (FeedForward(allow_extra_params=False,\n",
       "        arg_params={'squeeze_final_bias': <mxnet.ndarray.NDArray object at 0x2b5dc7b814d0>, 'squeeze_post_1_weight': <mxnet.ndarray.NDArray object at 0x2b5dc7b78d90>, 'decoder_bias': <mxnet.ndarray.NDArray object at 0x2b5dc7b81610>, 'squeeze_post_1_bias': <mxnet.ndarray.NDArray object at 0x2b5dc7b78c50>, 'squeeze_final_weight': <mxnet.ndarray.NDArray object at 0x2b5dc7b81690>, 'decoder_weight': <mxnet.ndarray.NDArray object at 0x2b5dc7b81210>},\n",
       "        aux_params={}, begin_epoch=0, ctx=[gpu(0), gpu(1)], epoch_size=None,\n",
       "        initializer=<mxnet.initializer.Uniform object at 0x2b5dbdc31dd0>,\n",
       "        num_epoch=20, numpy_batch_size=128,\n",
       "        optimizer=<myopt.MyAdaGrad object at 0x2b5dc8015fd0>,\n",
       "        symbol=<mxnet.symbol.Symbol object at 0x2b5dbdec9bd0>),\n",
       "  {'conv_constant': 8,\n",
       "   'conv_factor': 16,\n",
       "   'dilate_layers': 1,\n",
       "   'final_dropout': 0.1,\n",
       "   'final_num_features': 160,\n",
       "   'intermediate_dropout': 0.0,\n",
       "   'mult_factor': 2,\n",
       "   'squeeze_constant': 8,\n",
       "   'squeeze_factor': 1.0,\n",
       "   'weight_decay': 0.0},\n",
       "  ('mae', 0.052066597621887922)),\n",
       " (FeedForward(allow_extra_params=False,\n",
       "        arg_params={'squeeze_final_bias': <mxnet.ndarray.NDArray object at 0x2b5dc49ad310>, 'decoder_bias': <mxnet.ndarray.NDArray object at 0x2b5dc49ad910>, 'decoder_weight': <mxnet.ndarray.NDArray object at 0x2b5dc49ada50>, 'squeeze_final_weight': <mxnet.ndarray.NDArray object at 0x2b5dc49ad6d0>, 'squeeze...bject at 0x2b5dc49ade90>, 'squeeze_post_1_weight': <mxnet.ndarray.NDArray object at 0x2b5dc49bd950>},\n",
       "        aux_params={}, begin_epoch=0, ctx=[gpu(0), gpu(1)], epoch_size=None,\n",
       "        initializer=<mxnet.initializer.Uniform object at 0x2b5dbdc31dd0>,\n",
       "        num_epoch=20, numpy_batch_size=128,\n",
       "        optimizer=<myopt.MyAdaGrad object at 0x2b5dbdf48750>,\n",
       "        symbol=<mxnet.symbol.Symbol object at 0x2b5dc7b6b9d0>),\n",
       "  {'conv_constant': 8,\n",
       "   'conv_factor': 16,\n",
       "   'dilate_layers': 1,\n",
       "   'final_dropout': 0.1,\n",
       "   'final_num_features': 160,\n",
       "   'intermediate_dropout': 0.0,\n",
       "   'mult_factor': 2,\n",
       "   'squeeze_constant': 8,\n",
       "   'squeeze_factor': 1.0,\n",
       "   'weight_decay': 0.0},\n",
       "  ('mae', 0.02783476747572422)),\n",
       " (FeedForward(allow_extra_params=False,\n",
       "        arg_params={'squeeze_final_bias': <mxnet.ndarray.NDArray object at 0x2b5dc4a3a710>, 'squeeze_post_1_weight': <mxnet.ndarray.NDArray object at 0x2b5dc4a3a550>, 'decoder_bias': <mxnet.ndarray.NDArray object at 0x2b5dc4a3a5d0>, 'squeeze_post_1_bias': <mxnet.ndarray.NDArray object at 0x2b5dc4a3a650>, 's...Array object at 0x2b5dc4a3a790>, 'decoder_weight': <mxnet.ndarray.NDArray object at 0x2b5dc4a3ab50>},\n",
       "        aux_params={}, begin_epoch=0, ctx=[gpu(0), gpu(1)], epoch_size=None,\n",
       "        initializer=<mxnet.initializer.Uniform object at 0x2b5dbdc31dd0>,\n",
       "        num_epoch=20, numpy_batch_size=128,\n",
       "        optimizer=<myopt.MyAdaGrad object at 0x2b5dc49a37d0>,\n",
       "        symbol=<mxnet.symbol.Symbol object at 0x2b5dbdc3afd0>),\n",
       "  {'conv_constant': 8,\n",
       "   'conv_factor': 16,\n",
       "   'dilate_layers': 1,\n",
       "   'final_dropout': 0.1,\n",
       "   'final_num_features': 160,\n",
       "   'intermediate_dropout': 0.0,\n",
       "   'mult_factor': 2,\n",
       "   'squeeze_constant': 8,\n",
       "   'squeeze_factor': 1.0,\n",
       "   'weight_decay': 0.0},\n",
       "  ('mae', 0.034165979479439557)),\n",
       " (FeedForward(allow_extra_params=False,\n",
       "        arg_params={'squeeze_final_bias': <mxnet.ndarray.NDArray object at 0x2b5dc4a3fe50>, 'squeeze_post_1_weight': <mxnet.ndarray.NDArray object at 0x2b5dc4a3fed0>, 'decoder_bias': <mxnet.ndarray.NDArray object at 0x2b5dc4a3fc50>, 'squeeze_post_1_bias': <mxnet.ndarray.NDArray object at 0x2b5dc4a3f910>, 's...Array object at 0x2b5dc4a3fcd0>, 'decoder_weight': <mxnet.ndarray.NDArray object at 0x2b5dc4a3fc90>},\n",
       "        aux_params={}, begin_epoch=0, ctx=[gpu(0), gpu(1)], epoch_size=None,\n",
       "        initializer=<mxnet.initializer.Uniform object at 0x2b5dbdc31dd0>,\n",
       "        num_epoch=20, numpy_batch_size=128,\n",
       "        optimizer=<myopt.MyAdaGrad object at 0x2b5dc49bd850>,\n",
       "        symbol=<mxnet.symbol.Symbol object at 0x2b5dc496de90>),\n",
       "  {'conv_constant': 8,\n",
       "   'conv_factor': 16,\n",
       "   'dilate_layers': 1,\n",
       "   'final_dropout': 0.1,\n",
       "   'final_num_features': 160,\n",
       "   'intermediate_dropout': 0.0,\n",
       "   'mult_factor': 2,\n",
       "   'squeeze_constant': 8,\n",
       "   'squeeze_factor': 0.5,\n",
       "   'weight_decay': 0.0},\n",
       "  ('mae', 0.038254949264228344))]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:40:01 INFO:Auto-select kvstore type = local_update_cpu\n",
      "07:40:01 INFO:Start training with [gpu(0), gpu(1)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with {'squeeze_factor': 0.5, 'final_dropout': 0.1, 'intermediate_dropout': 0.0, 'conv_constant': 8, 'squeeze_constant': 8, 'mult_factor': 2, 'final_num_features': 160, 'conv_factor': 16, 'dilate_layers': 1, 'weight_decay': 0.0}\n",
      "Creating Model with params {'squeeze_factor': 0.5, 'final_dropout': 0.1, 'intermediate_dropout': 0.0, 'conv_constant': 8, 'squeeze_constant': 8, 'mult_factor': 2, 'final_num_features': 160, 'conv_factor': 16, 'dilate_layers': 1, 'weight_decay': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:40:01 INFO:Epoch[0] Batch [4]\tSpeed: 309.89 samples/sec\tTrain-mae=0.456967\n",
      "07:40:02 INFO:Epoch[0] Batch [8]\tSpeed: 226.00 samples/sec\tTrain-mae=0.294392\n",
      "07:40:02 INFO:Epoch[0] Batch [12]\tSpeed: 227.68 samples/sec\tTrain-mae=0.232851\n",
      "07:40:02 INFO:Epoch[0] Resetting Data Iterator\n",
      "07:40:02 INFO:Epoch[0] Time cost=1.687\n",
      "07:40:03 INFO:Epoch[0] Validation-mae=0.245401\n",
      "07:40:03 INFO:Epoch[1] Batch [4]\tSpeed: 309.52 samples/sec\tTrain-mae=0.223417\n",
      "07:40:04 INFO:Epoch[1] Batch [8]\tSpeed: 227.18 samples/sec\tTrain-mae=0.208210\n",
      "07:40:04 INFO:Epoch[1] Batch [12]\tSpeed: 227.62 samples/sec\tTrain-mae=0.215847\n",
      "07:40:04 INFO:Epoch[1] Resetting Data Iterator\n",
      "07:40:04 INFO:Epoch[1] Time cost=1.682\n",
      "07:40:05 INFO:Epoch[1] Validation-mae=0.232048\n",
      "07:40:05 INFO:Epoch[2] Batch [4]\tSpeed: 312.73 samples/sec\tTrain-mae=0.222416\n",
      "07:40:06 INFO:Epoch[2] Batch [8]\tSpeed: 227.93 samples/sec\tTrain-mae=0.206530\n",
      "07:40:06 INFO:Epoch[2] Batch [12]\tSpeed: 208.57 samples/sec\tTrain-mae=0.209587\n",
      "07:40:06 INFO:Epoch[2] Resetting Data Iterator\n",
      "07:40:06 INFO:Epoch[2] Time cost=1.726\n",
      "07:40:07 INFO:Epoch[2] Validation-mae=0.183694\n",
      "07:40:07 INFO:Epoch[3] Batch [4]\tSpeed: 310.57 samples/sec\tTrain-mae=0.206194\n",
      "07:40:08 INFO:Epoch[3] Batch [8]\tSpeed: 205.24 samples/sec\tTrain-mae=0.192104\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-113-0925d9595f0e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m\"Starting with %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhyperparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meval_hyperparams\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minframes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhyperparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhyperparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindowsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m96\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-109-f7b031438a4b>\u001b[0m in \u001b[0;36meval_hyperparams\u001b[1;34m(inframes, hyperparams, num_epoch, windowsize, batch_size, keep_prob, drop_pixel_x, drop_pixel_y)\u001b[0m\n\u001b[0;32m     59\u001b[0m               \u001b[0meval_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m               \u001b[0meval_metric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_metric\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m               batch_end_callback=mx.callback.Speedometer(batch_size, 4))\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhyperparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/data/learningtoreact/mymodel.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, eval_data, eval_metric, epoch_end_callback, batch_end_callback, kvstore, logger, work_load_list, monitor, eval_batch_end_callback)\u001b[0m\n\u001b[0;32m    787\u001b[0m                             \u001b[0mlogger\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwork_load_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwork_load_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                             \u001b[0meval_batch_end_callback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_batch_end_callback\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m                             sym_gen=self.sym_gen)\n\u001b[0m\u001b[0;32m    790\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/data/learningtoreact/mymodel.py\u001b[0m in \u001b[0;36m_train_multi_device\u001b[1;34m(symbol, ctx, arg_names, param_names, aux_names, arg_params, aux_params, begin_epoch, end_epoch, epoch_size, optimizer, kvstore, update_on_kvstore, train_data, eval_data, eval_metric, epoch_end_callback, batch_end_callback, logger, work_load_list, monitor, eval_batch_end_callback, sym_gen)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m                 \u001b[0mexecutor_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m                 \u001b[0mexecutor_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    229\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mupdate_on_kvstore\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/build/mxnet/python/mxnet/executor_manager.pyc\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    400\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m         \u001b[1;34m\"\"\"run backward on the current executor\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurr_execgrp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mupdate_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/build/mxnet/python/mxnet/executor_manager.pyc\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;34m\"\"\" Perform a backward pass on each executor \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtexec\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_execs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m             \u001b[0mtexec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mupdate_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/build/mxnet/python/mxnet/executor.pyc\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, out_grads)\u001b[0m\n\u001b[0;32m    135\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m             \u001b[0mmx_uint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m             ndarray))\n\u001b[0m\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mset_monitor_callback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "hyperparam_options = {\n",
    "    'dilate_layers' : [1],\n",
    "    'squeeze_factor' : [ 0.5, 1.0 ],\n",
    "    'mult_factor' : [ 2],\n",
    "    'squeeze_constant' : [ 8 ],\n",
    "    'conv_factor' : [ 16],\n",
    "    'conv_constant' : [ 8],\n",
    "    'intermediate_dropout' : [ 0.0],\n",
    "    'final_dropout' : [0.1],\n",
    "    'final_num_features' : [ 160],\n",
    "    'weight_decay' : [0.0]\n",
    "}\n",
    "\n",
    "\n",
    "for i in range(30):\n",
    "    hyperparams = sample_hyperparams(hyperparam_options)\n",
    "    display(results)\n",
    "    print \"Starting with %r\" % (hyperparams)\n",
    "    try:\n",
    "        res = eval_hyperparams(inframes, num_epoch=20, keep_prob=1.0, hyperparams=hyperparams, windowsize=96)\n",
    "        results.append(res)\n",
    "        model,hparams, metric = res\n",
    "        display(\"Result %d: Validation Accuracy: %r, Params: %r \" % (i, metric, hparams))\n",
    "    except Exception as e:\n",
    "        print \"Exception for hyperparams %r\" % (hyperparams)\n",
    "        results.append((None, hyperparams, None))\n",
    "        traceback.print_exc(e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def analyze_results(results):\n",
    "\n",
    "    param_analysis = defaultdict(lambda: defaultdict(lambda: []))\n",
    "    for model, hyperparams, eval_metric in results:\n",
    "        eval_result = 1.0\n",
    "        if (eval_metric is not None):\n",
    "        \n",
    "            eval_result = eval_metric[1]\n",
    "            \n",
    "        for param in hyperparams.keys():\n",
    "            value = hyperparams[param]\n",
    "            param_analysis[param][value].append(eval_result)\n",
    "            param_analysis[param][value] = sorted(param_analysis[param][value])\n",
    "    return param_analysis\n",
    "\n",
    "param_analysis = analyze_results(results)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dict(param_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def adef():\n",
    "        return []\n",
    "        \n",
    "def cdef():\n",
    "       return defaultdict(adef)\n",
    "  \n",
    "param_analysis = defaultdict(default_factory=cdef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net.list_arguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_middle_slice(net, inframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model, hyperparams = eval_hyperparams(inframes, num_epoch=5, hyperparam_options=hyperparam_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%debug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tile_batch_mask((1,1,16,16), 0.3, 8,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.num_epoch = 50\n",
    "model.load('dilated-autoencoder2_4', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.num_epoch = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "chunk_size = batch_size*32\n",
    "keep_prob = 0.9\n",
    "drop_pixel_x = 2\n",
    "drop_pixel_y = 2\n",
    "for i in range(69):\n",
    "    window_off_x =  np.random.randint(0, inframes.shape[2]-windowsize)\n",
    "    window_off_y = np.random.randint(0, inframes.shape[3]-windowsize)\n",
    "    start = np.random.randint(0, 1300-chunk_size)\n",
    "    train_X = inframes[start:start+chunk_size,:,window_off_x:window_off_x+windowsize,window_off_y:window_off_y+windowsize]\n",
    "    train_y = get_middle_slice(train_X)\n",
    "    mask_shape = list(train_X.shape)\n",
    "    mask_shape[1] = 1\n",
    "    mask = tile_batch_mask(mask_shape, keep_prob, drop_pixel_y, drop_pixel_y)\n",
    "    \n",
    "    train_X = np.concatenate((mask, train_X*mask), axis=1)\n",
    "    \n",
    "    test_X = inframes[1300:,:,window_off_x:window_off_x+windowsize,window_off_y:window_off_y+windowsize]\n",
    "    test_y = get_middle_slice(test_X)\n",
    "    test_mask_shape = list(test_X.shape)\n",
    "    test_mask_shape[1] = 1\n",
    "    if (i%2==0):\n",
    "        test_mask = tile_batch_mask(test_mask_shape, keep_prob, drop_pixel_y, drop_pixel_y)\n",
    "    else:\n",
    "        test_mask = tile_batch_mask(test_mask_shape, keep_prob, drop_pixel_y, drop_pixel_y)\n",
    "    \n",
    "    \n",
    "    test_X = np.concatenate((test_mask, test_X*test_mask), axis=1)\n",
    "    train_iter = mx.io.NDArrayIter({'data' : train_X}, { 'y' : train_y }, shuffle=True, batch_size=batch_size)\n",
    "    test_iter = mx.io.NDArrayIter({'data' : test_X}, { 'y' : test_y}, shuffle=True, batch_size=batch_size)\n",
    "    print \"New Windowed Batch %i\" % (i)\n",
    "    eval_metric = mx.metric.MAE()\n",
    "    model.fit(train_iter,\n",
    "          eval_data=test_iter,\n",
    "          eval_metric=eval_metric,\n",
    "          batch_end_callback=mx.callback.Speedometer(batch_size))\n",
    "    if (i % 5==4):\n",
    "        model.save('dilated-autoencoder2_%d' % (i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## MC Dropout Training / Validation Loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out.bind()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "executor=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_mc_dropout(mlp, ctx, train_iter, validation_iter, epochs=1,\n",
    "                     opt = mx.optimizer.Adam(wd=0.01), eval_metric=mx.metric.MAE(), init = mx.init.Uniform(scale=0.01), executor=None):\n",
    "    # data iterators defines shapes of its output with provide_data and provide_label property.\n",
    "    input_shapes = dict(train_iter.provide_data+train_iter.provide_label)\n",
    "\n",
    "    if (executor is not None):\n",
    "        exe = executor\n",
    "    else:\n",
    "        # We use simple_bind to let MXNet allocate memory for us.\n",
    "        # You can also allocate memory youself and use bind to pass it to MXNet.\n",
    "        exe = mlp.simple_bind(ctx=ctx, **input_shapes)\n",
    "\n",
    "    # ===============Initialization=================\n",
    "    # First we get handle to input arrays\n",
    "    arg_arrays = dict(zip(mlp.list_arguments(), exe.arg_arrays))\n",
    "    data = arg_arrays[train_iter.provide_data[0][0]]\n",
    "    label = arg_arrays[train_iter.provide_label[0][0]]\n",
    "\n",
    "    if (executor is None):\n",
    "\n",
    "        # We initialize the weights with uniform distribution on (-0.01, 0.01).\n",
    "\n",
    "        for name, arr in arg_arrays.items():\n",
    "            if name not in input_shapes:\n",
    "                init(name, arr)\n",
    "\n",
    "    # We also need to create an optimizer for updating weights\n",
    "    \n",
    "    updater = mx.optimizer.get_updater(opt)\n",
    "\n",
    "    # Finally we need a metric to print out training progress\n",
    "    metric = eval_metric\n",
    "\n",
    "    # Training loop begines\n",
    "    for epoch in range(epochs):\n",
    "        train_iter.reset()\n",
    "        metric.reset()\n",
    "        t = 0\n",
    "        for batch in train_iter:\n",
    "            # Copy data to executor input. Note the [:].\n",
    "            data[:] = batch.data[0]\n",
    "            label[:] = batch.label[0]\n",
    "\n",
    "            # Forward\n",
    "            exe.forward(is_train=True)\n",
    "\n",
    "            # You perform operations on exe.outputs here if you need to.\n",
    "            # For example, you can stack a CRF on top of a neural network.\n",
    "\n",
    "            # Backward\n",
    "            exe.backward()\n",
    "\n",
    "            # Update\n",
    "            for i, pair in enumerate(zip(exe.arg_arrays, exe.grad_arrays)):\n",
    "                weight, grad = pair\n",
    "                updater(i, grad, weight)\n",
    "            metric.update(batch.label, exe.outputs)\n",
    "            t += 1\n",
    "            if t % 10 == 0:\n",
    "                print 'epoch:', epoch, 'iter:', t, 'metric:', metric.get()  \n",
    "    return exe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = results[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m.sum_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "executor = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "import ctypes\n",
    "import sys\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "from mxnet.ndarray import NDArray\n",
    "from mxnet.ndarray import array\n",
    "from mxnet.io import DataIter, DataBatch\n",
    "\n",
    "class RandomImageSlicingNDArrayIter(DataIter):\n",
    "    \"\"\"NDArrayIter object in mxnet. Taking NDArray or numpy array to get dataiter.\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: NDArray or numpy.ndarray, a list of them, or a dict of string to them.\n",
    "        NDArrayIter supports single or multiple data and label.\n",
    "    label: NDArray or numpy.ndarray, a list of them, or a dict of them.\n",
    "        Same as data, but is not fed to the model during testing.\n",
    "    batch_size: int\n",
    "        Batch Size\n",
    "    shuffle: bool\n",
    "        Whether to shuffle the data\n",
    "    last_batch_handle: 'pad', 'discard' or 'roll_over'\n",
    "        How to handle the last batch\n",
    "    Note\n",
    "    ----\n",
    "    This iterator will pad, discard or roll over the last batch if\n",
    "    the size of data does not match batch_size. Roll over is intended\n",
    "    for training and can cause problems if used for prediction.\n",
    "    \"\"\"\n",
    "    def __init__(self, data, label=None, batch_size=1, shuffle=False, last_batch_handle='pad'):\n",
    "        # pylint: disable=W0201\n",
    "\n",
    "        super(RandomImageSlicingNDArrayIter, self).__init__()\n",
    "\n",
    "        self.data = _init_data(data, allow_empty=False, default_name='data')\n",
    "        self.label = _init_data(label, allow_empty=True, default_name='softmax_label')\n",
    "\n",
    "        # shuffle data\n",
    "        if shuffle:\n",
    "            idx = np.arange(self.data[0][1].shape[0])\n",
    "            np.random.shuffle(idx)\n",
    "            self.data = [(k, v[idx]) for k, v in self.data]\n",
    "            self.label = [(k, v[idx]) for k, v in self.label]\n",
    "\n",
    "        self.data_list = [x[1] for x in self.data] + [x[1] for x in self.label]\n",
    "        self.num_source = len(self.data_list)\n",
    "\n",
    "        # batching\n",
    "        if last_batch_handle == 'discard':\n",
    "            new_n = self.data_list[0].shape[0] - self.data_list[0].shape[0] % batch_size\n",
    "            data_dict = OrderedDict(self.data)\n",
    "            label_dict = OrderedDict(self.label)\n",
    "            for k, _ in self.data:\n",
    "                data_dict[k] = data_dict[k][:new_n]\n",
    "            for k, _ in self.label:\n",
    "                label_dict[k] = label_dict[k][:new_n]\n",
    "            self.data = data_dict.items()\n",
    "            self.label = label_dict.items()\n",
    "        self.num_data = self.data_list[0].shape[0]\n",
    "        assert self.num_data >= batch_size, \\\n",
    "            \"batch_size need to be smaller than data size.\"\n",
    "        self.cursor = -batch_size\n",
    "        self.batch_size = batch_size\n",
    "        self.last_batch_handle = last_batch_handle\n",
    "\n",
    "    @property\n",
    "    def provide_data(self):\n",
    "        \"\"\"The name and shape of data provided by this iterator\"\"\"\n",
    "        return [(k, tuple([self.batch_size] + list(v.shape[1:]))) for k, v in self.data]\n",
    "\n",
    "    @property\n",
    "    def provide_label(self):\n",
    "        \"\"\"The name and shape of label provided by this iterator\"\"\"\n",
    "        return [(k, tuple([self.batch_size] + list(v.shape[1:]))) for k, v in self.label]\n",
    "\n",
    "\n",
    "    def hard_reset(self):\n",
    "        \"\"\"Igore roll over data and set to start\"\"\"\n",
    "        self.cursor = -self.batch_size\n",
    "\n",
    "    def reset(self):\n",
    "        if self.last_batch_handle == 'roll_over' and self.cursor > self.num_data:\n",
    "            self.cursor = -self.batch_size + (self.cursor%self.num_data)%self.batch_size\n",
    "        else:\n",
    "            self.cursor = -self.batch_size\n",
    "\n",
    "    def iter_next(self):\n",
    "        self.cursor += self.batch_size\n",
    "        if self.cursor < self.num_data:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def next(self):\n",
    "        if self.iter_next():\n",
    "            return DataBatch(data=self.getdata(), label=self.getlabel(), \\\n",
    "                    pad=self.getpad(), index=None)\n",
    "        else:\n",
    "            raise StopIteration\n",
    "\n",
    "    def _getdata(self, data_source):\n",
    "        \"\"\"Load data from underlying arrays, internal use only\"\"\"\n",
    "        assert(self.cursor < self.num_data), \"DataIter needs reset.\"\n",
    "        if self.cursor + self.batch_size <= self.num_data:\n",
    "            return [array(x[1][self.cursor:self.cursor+self.batch_size]) for x in data_source]\n",
    "        else:\n",
    "            pad = self.batch_size - self.num_data + self.cursor\n",
    "            return [array(np.concatenate((x[1][self.cursor:], x[1][:pad]),\n",
    "                                         axis=0)) for x in data_source]\n",
    "\n",
    "    def getdata(self):\n",
    "        return self._getdata(self.data)\n",
    "\n",
    "    def getlabel(self):\n",
    "        return self._getdata(self.label)\n",
    "\n",
    "    def getpad(self):\n",
    "        if self.last_batch_handle == 'pad' and \\\n",
    "           self.cursor + self.batch_size > self.num_data:\n",
    "            return self.cursor + self.batch_size - self.num_data\n",
    "        else:\n",
    "            return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chunk_size = batch_size*32\n",
    "keep_prob = 0.9\n",
    "drop_pixel_x = 2\n",
    "drop_pixel_y = 2\n",
    "\n",
    "for i in range(3):\n",
    "    window_off_x =  np.random.randint(0, inframes.shape[2]-windowsize)\n",
    "    window_off_y = np.random.randint(0, inframes.shape[3]-windowsize)\n",
    "    start = np.random.randint(0, inframes.shape[0]-1000-chunk_size)\n",
    "    train_X = inframes[start:start+chunk_size,:,window_off_x:window_off_x+windowsize,window_off_y:window_off_y+windowsize]\n",
    "    train_y = get_middle_slice(train_X)\n",
    "    mask_shape = list(train_X.shape)\n",
    "    mask_shape[1] = 1\n",
    "    mask = tile_batch_mask(mask_shape, keep_prob, drop_pixel_y, drop_pixel_y)\n",
    "    \n",
    "    train_X = np.concatenate((mask, train_X*mask), axis=1)\n",
    "    \n",
    "    test_X = inframes[inframes.shape[0]-1000:inframes.shape[0]-800,:,window_off_x:window_off_x+windowsize,window_off_y:window_off_y+windowsize]\n",
    "    test_y = get_middle_slice(test_X)\n",
    "    test_mask_shape = list(test_X.shape)\n",
    "    test_mask_shape[1] = 1\n",
    "    if (i%2==0):\n",
    "        test_mask = tile_batch_mask(test_mask_shape, keep_prob, drop_pixel_y, drop_pixel_y)\n",
    "    else:\n",
    "        test_mask = tile_batch_mask(test_mask_shape, keep_prob, drop_pixel_y, drop_pixel_y)\n",
    "    \n",
    "    \n",
    "    test_X = np.concatenate((test_mask, test_X*test_mask), axis=1)\n",
    "    train_iter = mx.io.NDArrayIter({'data' : train_X}, { 'y' : train_y }, shuffle=True, batch_size=batch_size)\n",
    "    test_iter = mx.io.NDArrayIter({'data' : test_X}, { 'y' : test_y}, shuffle=True, batch_size=batch_size)\n",
    "    print \"New Windowed Batch %i\" % (i)\n",
    "    executor = train_mc_dropout(out, ctx=mx.gpu(0), train_iter=train_iter, validation_iter=test_iter, executor=executor)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "size = 0\n",
    "for k in model.arg_params:\n",
    "    size += np.prod(model.arg_params[k].shape)\n",
    "print \"Model size: \",size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out.list_arguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arg_shape, out_shape, aux_shape = out.infer_shape(X=(10, 3, 640,480), y=(10,3,270,110))\n",
    "dict(zip(net.list_arguments(), arg_shape))\n",
    "size = 0\n",
    "for s in arg_shape:\n",
    "    print s\n",
    "    size += np.prod(s)\n",
    "print \"Total parameter size=%d MB, total temp size=%d MB\" % (size / (1024*1024), 640*480*1000*8 / (1024*1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net.list_arguments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note\n",
    "\n",
    "\n",
    " * Important Paper about Dilated Convolution: http://arxiv.org/pdf/1511.07122v1.pdf\n",
    "\n",
    " * Deep Probabilistic Inference Models http://gitxiv.com/posts/oRw692PEooNcwh9Qh/neural-variational-inference-for-text-processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Visualizing the reconstructed video ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!mkdir imageseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!rm imageseries/*.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask = tile_batch_mask((1,1,360, 640), 1.0, 4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "j = 0\n",
    "c = 0\n",
    "\n",
    "for i in permuted_indices:    \n",
    "    #print np.sum(hsvimg-hsvimg2)\n",
    "    fframe = inframes[i,:,:,:] # np.transpose(inframes[i,:,:,:], [1,2,0])\n",
    "    fframe = fframe[np.newaxis,:,:,:]\n",
    "    mfframe = np.concatenate((mask, fframe*mask), axis=1)\n",
    "    print mfframe.shape\n",
    "    mfframe = mfframe[0:1,:,100:164,100:164]\n",
    "    clipfframe = fframe[0:1,:,100:164,100:164]\n",
    "    bgi =  mx.io.NDArrayIter({'data' : mfframe}, batch_size=1)\n",
    "    \n",
    "    pframe = model.predict(bgi, num_batch=1)[0]\n",
    "    print \"Mean, Std\"\n",
    "    print np.mean(pframe[0,:,:])\n",
    "    print np.mean(pframe[1,:,:])\n",
    "    print np.mean(pframe[2,:,:])\n",
    "    \n",
    "    \n",
    "    print np.std(pframe[0,:,:])\n",
    "    print np.std(pframe[1,:,:])\n",
    "    print np.std(pframe[2,:,:])\n",
    "    \n",
    "    pframe = np.clip(pframe, 0.0, 1.0, pframe)\n",
    "    print pframe.shape\n",
    "    print pframe.dtype\n",
    "    \n",
    "    px = pframe.shape[1]\n",
    "    py = pframe.shape[2]\n",
    "    offx = (clipfframe.shape[2]-px)/2\n",
    "    offy = (clipfframe.shape[3]-py)/2\n",
    "    print offx\n",
    "    print offy\n",
    "    \n",
    "    mae = np.mean(np.abs(clipfframe[0,:,offx:px+offx,offy:py+offy]-pframe))\n",
    "    print \"MAE = %f\" % (mae)\n",
    "    \n",
    "    pframe = (pframe * 255.0).astype(np.uint8)\n",
    "    piframe = np.transpose(pframe, [1,2,0])\n",
    "    bgrimg = cv2.cvtColor(piframe, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    j+=1\n",
    "    c+=1\n",
    "    cv2.imwrite(\"imageseries/reconstruction1_%05d.jpg\" % (c), bgrimg)\n",
    "    if (c>400):\n",
    "        break\n",
    "    if (j % 10==0):\n",
    "        print \"frame %d\" % (c)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "display(Image('imageseries/reconstruction1_00002.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!rm imageseries/*.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!rm videos/Chimpanzees1_reconstructed3.mp4\n",
    "!ffmpeg -i imageseries/reconstruction1_%05d.jpg -c:v libx264 -b:v 400k -maxrate:v 500k -bufsize 1000k -r 10 -preset medium videos/Chimpanzees1_reconstructed3.mp4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!ls -hs imageseries/recons*.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display(Image('imageseries/reconstruction1_00052.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "link_video('videos/Chimpanzees1_reconstructed3.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "display(FileLink('videos/Chimpanzees1_reconstructed3.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "link_video('videos/Chimpanzees1_reconstructed3.mp4')\n",
    "#link_video('videos/Chimpanzees1_reconstructed2.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "link_video('videos/Chimpanzees1.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display(FileLink('videos/Chimpanzees1_reconstructed2.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MultiplyMaskOp(mx.operator.CustomOp):\n",
    "    \n",
    "    def forward(self, is_train, req, in_data, out_data, aux):\n",
    "        img_channels = in_data[1].asnumpy()\n",
    "        mask = in_data[0].asnumpy()\n",
    "        \n",
    "        if req[0]=='null':\n",
    "            return\n",
    "        \n",
    "        shp = list(img_channels.shape)\n",
    "        shp[1] += 1\n",
    "        \n",
    "        out = np.zeros(shape=tuple(shp))\n",
    "        out[:,0:1,:,:] = mask\n",
    "        out[:,1:,:,:] = img_channels*mask # Automatic broadcasting to the rescue\n",
    "        \n",
    "        if req[0]=='write':\n",
    "            out_data[0][:] = out\n",
    "        elif req[0]=='add':\n",
    "            out_data[0][:] += out\n",
    "                \n",
    "    def backward(self, req, out_grad, in_data, out_data, in_grad, aux):\n",
    "        if req[0]=='null':\n",
    "            return\n",
    "        \n",
    "        mask = in_data[0]\n",
    "        img_channels = in_data[1]\n",
    "        \n",
    "        img_grad = out_data[:,1:]\n",
    "        mask_grad = out_data[:,0:1]\n",
    "        \n",
    "        # Gradient of mask is copied through\n",
    "        \n",
    "        if req[0]=='write':\n",
    "            in_grad[0][:] = mask_grad\n",
    "        elif req[0]=='add':\n",
    "            in_grad[0][:] += mask_grad\n",
    "           \n",
    "        img_grad = np.ones(img_channels.shape)\n",
    "        for i in range(3):\n",
    "            # Product rule applies for image channels\n",
    "            chan_grad = mx.nd.add(mx.nd.multiply(img_channels[:,i:i+1], mask_grad), \n",
    "                                  mx.nd.multiply(img_grad[:,i:i+1], mask) )\n",
    "            img_grad[:,i,:,:] = chan.asnumpy()\n",
    "            \n",
    "        if req[1]=='write':\n",
    "            in_grad[1][:] = img_grad    \n",
    "        elif req[1]=='add':\n",
    "            in_grad[1][:] += img_grad\n",
    "            \n",
    "@mx.operator.register(\"maskmult\")\n",
    "class MultiplyMaskOpProp(mx.operator.CustomOpProp):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MultiplyMaskOpProp, self).__init__()\n",
    "        \n",
    "    def list_arguments(self):\n",
    "        return ['mask', 'data']\n",
    "\n",
    "    def list_outputs(self):\n",
    "        return ['masked_data']\n",
    "\n",
    "    def infer_shape(self, in_shape):\n",
    "        mask_shape = list(in_shape[0])\n",
    "        data_shape = list(in_shape[1])\n",
    "        data_shape[1]+=1\n",
    "        return in_shape, [data_shape], []\n",
    "    \n",
    "    def create_operator(self, ctx, shapes, dtypes):\n",
    "        return MultiplyMaskOp()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(b*a).grad(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
